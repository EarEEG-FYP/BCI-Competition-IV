{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil \n",
    "import time \n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.io import read_raw_edf\n",
    "from dateutil.parser import parse \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.regularizers import L2\n",
    "from keras.constraints import max_norm\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, Activation, AveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv1D, Conv2D, SeparableConv2D, DepthwiseConv2D, MultiHeadAttention\n",
    "from keras.layers import BatchNormalization, LayerNormalization, Flatten\n",
    "from keras.layers import Add, multiply, Concatenate, Lambda, Input, Permute, Reshape\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two datasets are used for the training and testing. The second dataset might not be required for the ATCNet model and might be used only for other models.\n",
    "1. BCI Competition IV 2a\n",
    "2. CS2R Dataset V2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. BCI Competition IV 2a Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_BCI2a_data(data_path, subject, training, all_trials = True):\n",
    "    \"\"\" Loading and Dividing of the data set based on the subject-specific \n",
    "    (subject-dependent) approach.\n",
    "    In this approach, we used the same training and testing dataas the original\n",
    "    competition, i.e., 288 x 9 trials in session 1 for training, \n",
    "    and 288 x 9 trials in session 2 for testing.  \n",
    "   \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string\n",
    "            dataset path\n",
    "            # Dataset BCI Competition IV-2a is available on \n",
    "            # http://bnci-horizon-2020.eu/database/data-sets\n",
    "        subject: int\n",
    "            number of subject in [1, .. ,9]\n",
    "        training: bool\n",
    "            if True, load training data\n",
    "            if False, load testing data\n",
    "        all_trials: bool\n",
    "            if True, load all trials\n",
    "            if False, ignore trials with artifacts \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define MI-trials parameters\n",
    "    n_channels = 22\n",
    "    n_tests = 6*48     \n",
    "    window_Length = 7*250 \n",
    "    \n",
    "    # Define MI trial window \n",
    "    fs = 250          # sampling rate\n",
    "    t1 = int(1.5*fs)  # start time_point\n",
    "    t2 = int(6*fs)    # end time_point\n",
    "\n",
    "    class_return = np.zeros(n_tests)\n",
    "    data_return = np.zeros((n_tests, n_channels, window_Length))\n",
    "\n",
    "    NO_valid_trial = 0\n",
    "    if training:\n",
    "        a = sio.loadmat(data_path+'A0'+str(subject)+'T.mat')\n",
    "    else:\n",
    "        a = sio.loadmat(data_path+'A0'+str(subject)+'E.mat')\n",
    "    a_data = a['data']\n",
    "    for ii in range(0,a_data.size):\n",
    "        a_data1 = a_data[0,ii]\n",
    "        a_data2= [a_data1[0,0]]\n",
    "        a_data3= a_data2[0]\n",
    "        a_X         = a_data3[0]\n",
    "        a_trial     = a_data3[1]\n",
    "        a_y         = a_data3[2]\n",
    "        a_artifacts = a_data3[5]\n",
    "\n",
    "        for trial in range(0,a_trial.size):\n",
    "             if(a_artifacts[trial] != 0 and not all_trials):\n",
    "                 continue\n",
    "             data_return[NO_valid_trial,:,:] = np.transpose(a_X[int(a_trial[trial]):(int(a_trial[trial])+window_Length),:22])\n",
    "             class_return[NO_valid_trial] = int(a_y[trial])\n",
    "             NO_valid_trial +=1        \n",
    "    \n",
    "\n",
    "    data_return = data_return[0:NO_valid_trial, :, t1:t2]\n",
    "    class_return = class_return[0:NO_valid_trial]\n",
    "    class_return = (class_return-1).astype(int)\n",
    "\n",
    "    return data_return, class_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Loading CS2R Dataset v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CS2R_data_v2(data_path, subject, training, \n",
    "                      classes_labels =  ['Fingers', 'Wrist','Elbow','Rest'], \n",
    "                      all_trials = True):\n",
    "    \"\"\" Loading training/testing data for the CS2R motor imagery dataset\n",
    "    for a specific subject        \n",
    "   \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string\n",
    "            dataset path\n",
    "        subject: int\n",
    "            number of subject in [1, .. ,9]\n",
    "        training: bool\n",
    "            if True, load training data\n",
    "            if False, load testing data\n",
    "        classes_labels: tuple\n",
    "            classes of motor imagery returned by the method (default: all) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all subjects files with .edf format.\n",
    "    subjectFiles = glob.glob(data_path + 'S_*/')\n",
    "    \n",
    "    # Get all subjects numbers sorted without duplicates.\n",
    "    subjectNo = list(dict.fromkeys(sorted([x[len(x)-4:len(x)-1] for x in subjectFiles])))\n",
    "    # print(SubjectNo[subject].zfill(3))\n",
    "    \n",
    "    if training:  session = 1\n",
    "    else:         session = 2\n",
    "    \n",
    "    num_runs = 5\n",
    "    sfreq = 250 #250\n",
    "    mi_duration = 4.5 #4.5\n",
    "\n",
    "    data = np.zeros([num_runs*51, 32, int(mi_duration*sfreq)])\n",
    "    classes = np.zeros(num_runs * 51)\n",
    "    valid_trails = 0\n",
    "    \n",
    "    onset = np.zeros([num_runs, 51])\n",
    "    duration = np.zeros([num_runs, 51])\n",
    "    description = np.zeros([num_runs, 51])\n",
    "\n",
    "    #Loop to the first 4 runs.\n",
    "    CheckFiles = glob.glob(data_path + 'S_' + subjectNo[subject].zfill(3) + '/S' + str(session) + '/*.edf')\n",
    "    if not CheckFiles:\n",
    "        return \n",
    "    \n",
    "    for runNo in range(num_runs): \n",
    "        valid_trails_in_run = 0\n",
    "        #Get .edf and .json file for following subject and run.\n",
    "        EDFfile = glob.glob(data_path + 'S_' + subjectNo[subject].zfill(3) + '/S' + str(session) + '/S_'+subjectNo[subject].zfill(3)+'_'+str(session)+str(runNo+1)+'*.edf')\n",
    "        JSONfile = glob.glob(data_path + 'S_'+subjectNo[subject].zfill(3) + '/S'+ str(session) +'/S_'+subjectNo[subject].zfill(3)+'_'+str(session)+str(runNo+1)+'*.json')\n",
    "    \n",
    "        #Check if EDFfile list is empty\n",
    "        if not EDFfile:\n",
    "          continue\n",
    "    \n",
    "        # We use mne.read_raw_edf to read in the .edf EEG files\n",
    "        raw = read_raw_edf(str(EDFfile[0]), preload=True, verbose=False)\n",
    "        \n",
    "        # Opening JSON file of the current RUN.\n",
    "        f = open(JSONfile[0],) \n",
    "    \n",
    "        # returns JSON object as a dictionary \n",
    "        JSON = json.load(f) \n",
    "    \n",
    "        #Number of Keystrokes Markers\n",
    "        keyStrokes = np.min([len(JSON['Markers']), 51]) #len(JSON['Markers']), to avoid extra markers by accident\n",
    "        # MarkerStart = JSON['Markers'][0]['startDatetime']\n",
    "           \n",
    "        #Get Start time of marker\n",
    "        date_string = EDFfile[0][-21:-4]\n",
    "        datetime_format = \"%d.%m.%y_%H.%M.%S\"\n",
    "        startRecordTime = datetime.strptime(date_string, datetime_format).astimezone()\n",
    "    \n",
    "        currentTrialNo = 0 # 1 = fingers, 2 = Wrist, 3 = Elbow, 4 = rest\n",
    "        if(runNo == 4): \n",
    "            currentTrialNo = 4\n",
    "    \n",
    "        ch_names = raw.info['ch_names'][4:36]\n",
    "             \n",
    "        # filter the data \n",
    "        raw.filter(4., 50., fir_design='firwin')  \n",
    "        \n",
    "        raw = raw.copy().pick_channels(ch_names = ch_names)\n",
    "        raw = raw.copy().resample(sfreq = sfreq)\n",
    "        fs = raw.info['sfreq']\n",
    "\n",
    "        for trail in range(keyStrokes):\n",
    "            \n",
    "            # class for current trial\n",
    "            if(runNo == 4 ):               # In Run 5 all trials are 'reset'\n",
    "                currentTrialNo = 4\n",
    "            elif (currentTrialNo == 3):    # Set the class of current trial to 1 'Fingers'\n",
    "                currentTrialNo = 1   \n",
    "            else:                          # In Runs 1-4, 1st trial is 1 'Fingers', 2nd trial is 2 'Wrist', and 3rd trial is 'Elbow', and repeat ('Fingers', 'Wrist', 'Elbow', ..)\n",
    "                currentTrialNo = currentTrialNo + 1\n",
    "                \n",
    "            trailDuration = 8\n",
    "            \n",
    "            trailTime = parse(JSON['Markers'][trail]['startDatetime'])\n",
    "            trailStart = trailTime - startRecordTime\n",
    "            trailStart = trailStart.seconds \n",
    "            start = trailStart + (6 - mi_duration)\n",
    "            stop = trailStart + 6\n",
    "\n",
    "            if (trail < keyStrokes-1):\n",
    "                trailDuration = parse(JSON['Markers'][trail+1]['startDatetime']) - parse(JSON['Markers'][trail]['startDatetime'])\n",
    "                trailDuration =  trailDuration.seconds + (trailDuration.microseconds/1000000)\n",
    "                if (trailDuration < 7.5) or (trailDuration > 8.5):\n",
    "                    print('In Session: {} - Run: {}, Trail no: {} is skipped due to short/long duration of: {:.2f}'.format(session, (runNo+1), (trail+1), trailDuration))\n",
    "                    if (trailDuration > 14 and trailDuration < 18):\n",
    "                        if (currentTrialNo == 3):   currentTrialNo = 1   \n",
    "                        else:                       currentTrialNo = currentTrialNo + 1\n",
    "                    continue\n",
    "                \n",
    "            elif (trail == keyStrokes-1):\n",
    "                trailDuration = raw[0, int(trailStart*int(fs)):int((trailStart+8)*int(fs))][0].shape[1]/fs\n",
    "                if (trailDuration < 7.8) :\n",
    "                    print('In Session: {} - Run: {}, Trail no: {} is skipped due to short/long duration of: {:.2f}'.format(session, (runNo+1), (trail+1), trailDuration))\n",
    "                    continue\n",
    "\n",
    "            MITrail = raw[:32, int(start*int(fs)):int(stop*int(fs))][0]\n",
    "            if (MITrail.shape[1] != data.shape[2]):\n",
    "                print('Error in Session: {} - Run: {}, Trail no: {} due to the lost of data'.format(session, (runNo+1), (trail+1)))\n",
    "                return\n",
    "            \n",
    "            # select some specific classes\n",
    "            if ((('Fingers' in classes_labels) and (currentTrialNo==1)) or \n",
    "            (('Wrist' in classes_labels) and (currentTrialNo==2)) or \n",
    "            (('Elbow' in classes_labels) and (currentTrialNo==3)) or \n",
    "            (('Rest' in classes_labels) and (currentTrialNo==4))):\n",
    "                data[valid_trails] = MITrail\n",
    "                classes[valid_trails] =  currentTrialNo\n",
    "                \n",
    "                # For Annotations\n",
    "                onset[runNo, valid_trails_in_run]  = start\n",
    "                duration[runNo, valid_trails_in_run] = trailDuration - (6 - mi_duration)\n",
    "                description[runNo, valid_trails_in_run] = currentTrialNo\n",
    "                valid_trails += 1\n",
    "                valid_trails_in_run += 1\n",
    "                         \n",
    "    data = data[0:valid_trails, :, :]\n",
    "    classes = classes[0:valid_trails]\n",
    "    classes = (classes-1).astype(int)\n",
    "\n",
    "    return data, classes, onset, duration, description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. LOSO (Leave One Subject Out)  \n",
    "\n",
    "This loads one of the datasets out of the above two and seprate the (X_train, y_train, X_test, y_test) using the LOSO method. This is applicable during the subject independat training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_LOSO (data_path, subject, dataset): \n",
    "    \"\"\" Loading and Dividing of the data set based on the \n",
    "    'Leave One Subject Out' (LOSO) evaluation approach. \n",
    "    LOSO is used for  Subject-independent evaluation.\n",
    "    In LOSO, the model is trained and evaluated by several folds, equal to the \n",
    "    number of subjects, and for each fold, one subject is used for evaluation\n",
    "    and the others for training. The LOSO evaluation technique ensures that \n",
    "    separate subjects (not visible in the training data) are usedto evaluate \n",
    "    the model.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string\n",
    "            dataset path\n",
    "            # Dataset BCI Competition IV-2a is available at \n",
    "            # http://bnci-horizon-2020.eu/database/data-sets\n",
    "        subject: int\n",
    "            number of subject in [1, .. ,9/14]\n",
    "            Here, the subject data is used  test the model and other subjects data\n",
    "            for training\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, y_train = [], []\n",
    "    for sub in range (0,9):\n",
    "        path = data_path+'s' + str(sub+1) + '/'\n",
    "        \n",
    "        if (dataset == 'BCI2a'):\n",
    "            X1, y1 = load_BCI2a_data(path, sub+1, True)\n",
    "            X2, y2 = load_BCI2a_data(path, sub+1, False)\n",
    "        elif (dataset == 'CS2R'):\n",
    "            X1, y1, _, _, _  = load_CS2R_data_v2(path, sub, True)\n",
    "            X2, y2, _, _, _  = load_CS2R_data_v2(path, sub, False)\n",
    "        # elif (dataset == 'HGD'):\n",
    "        #     X1, y1 = load_HGD_data(path, sub+1, True)\n",
    "        #     X2, y2 = load_HGD_data(path, sub+1, False)\n",
    "        \n",
    "        X = np.concatenate((X1, X2), axis=0)\n",
    "        y = np.concatenate((y1, y2), axis=0)\n",
    "                   \n",
    "        if (sub == subject):\n",
    "            X_test = X\n",
    "            y_test = y\n",
    "        elif (X_train == []):\n",
    "            X_train = X\n",
    "            y_train = y\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X), axis=0)\n",
    "            y_train = np.concatenate((y_train, y), axis=0)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Standardizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X_train, X_test, channels): \n",
    "    # X_train & X_test :[Trials, MI-tasks, Channels, Time points]\n",
    "    for j in range(channels):\n",
    "          scaler = StandardScaler()\n",
    "          scaler.fit(X_train[:, 0, j, :])\n",
    "          X_train[:, 0, j, :] = scaler.transform(X_train[:, 0, j, :])\n",
    "          X_test[:, 0, j, :] = scaler.transform(X_test[:, 0, j, :])\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. get_data  \n",
    "\n",
    "This combines the data loading and preprocessing methods into one function. \n",
    "\n",
    "If the method is subject independant then LOSO should not be used. \n",
    "\n",
    "For such cases, Train/Test Split is handled within this funciton. In such subject specific method is used, the train and split is done to each subject seperately. This split is done as it was done in BCI Competition IV dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, subject, dataset = 'BCI2a', classes_labels = 'all', LOSO = False, isStandard = True, isShuffle = True):\n",
    "    \n",
    "    # Load and split the dataset into training and testing \n",
    "    if LOSO:\n",
    "        \"\"\" Loading and Dividing of the dataset based on the \n",
    "        'Leave One Subject Out' (LOSO) evaluation approach. \"\"\" \n",
    "        X_train, y_train, X_test, y_test = load_data_LOSO(path, subject, dataset)\n",
    "    else:\n",
    "        \"\"\" Loading and Dividing of the data set based on the subject-specific \n",
    "        (subject-dependent) approach.\n",
    "        In this approach, we used the same training and testing data as the original\n",
    "        competition, i.e., for BCI Competition IV-2a, 288 x 9 trials in session 1 \n",
    "        for training, and 288 x 9 trials in session 2 for testing.  \n",
    "        \"\"\"\n",
    "        if (dataset == 'BCI2a'):\n",
    "            path = path + 's{:}/'.format(subject+1)\n",
    "            X_train, y_train = load_BCI2a_data(path, subject+1, True)\n",
    "            X_test, y_test = load_BCI2a_data(path, subject+1, False)\n",
    "        elif (dataset == 'CS2R'):\n",
    "            X_train, y_train, _, _, _ = load_CS2R_data_v2(path, subject, True, classes_labels)\n",
    "            X_test, y_test, _, _, _ = load_CS2R_data_v2(path, subject, False, classes_labels)\n",
    "        # elif (dataset == 'HGD'):\n",
    "        #     X_train, y_train = load_HGD_data(path, subject+1, True)\n",
    "        #     X_test, y_test = load_HGD_data(path, subject+1, False)\n",
    "        else:\n",
    "            raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "\n",
    "    # shuffle the data \n",
    "    if isShuffle:\n",
    "        X_train, y_train = shuffle(X_train, y_train,random_state=42)\n",
    "        X_test, y_test = shuffle(X_test, y_test,random_state=42)\n",
    "\n",
    "    # Prepare training data     \n",
    "    N_tr, N_ch, T = X_train.shape \n",
    "    X_train = X_train.reshape(N_tr, 1, N_ch, T)\n",
    "    y_train_onehot = to_categorical(y_train)\n",
    "    # Prepare testing data \n",
    "    N_tr, N_ch, T = X_test.shape \n",
    "    X_test = X_test.reshape(N_tr, 1, N_ch, T)\n",
    "    y_test_onehot = to_categorical(y_test)    \n",
    "    \n",
    "    # Standardize the data\n",
    "    if isStandard:\n",
    "        X_train, X_test = standardize_data(X_train, X_test, N_ch)\n",
    "\n",
    "    return X_train, y_train, y_train_onehot, X_test, y_test, y_test_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining The Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Conv_block (Models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_block_(input_layer, F1=4, kernLength=64, poolSize=8, D=2, in_chans=22, \n",
    "                weightDecay = 0.009, maxNorm = 0.6, dropout=0.25):\n",
    "    \"\"\" Conv_block\n",
    "    \n",
    "        Notes\n",
    "        -----\n",
    "        using  different regularization methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    F2= F1*D\n",
    "    block1 = Conv2D(F1, (kernLength, 1), padding = 'same', data_format='channels_last', \n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    \n",
    "                    # In a Conv2D layer with data_format=\"channels_last\", the weight tensor has shape \n",
    "                    # (rows, cols, input_depth, output_depth), set axis to [0, 1, 2] to constrain \n",
    "                    # the weights of each filter tensor of size (rows, cols, input_depth).\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1,2]),\n",
    "                    use_bias = False)(input_layer)\n",
    "    block1 = BatchNormalization(axis = -1)(block1)  # bn_axis = -1 if data_format() == 'channels_last' else 1\n",
    "    \n",
    "    block2 = DepthwiseConv2D((1, in_chans),  \n",
    "                             depth_multiplier = D,\n",
    "                             data_format='channels_last',\n",
    "                             depthwise_regularizer=L2(weightDecay),\n",
    "                             depthwise_constraint  = max_norm(maxNorm, axis=[0,1,2]),\n",
    "                             use_bias = False)(block1)\n",
    "    block2 = BatchNormalization(axis = -1)(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = AveragePooling2D((8,1),data_format='channels_last')(block2)\n",
    "    block2 = Dropout(dropout)(block2)\n",
    "    \n",
    "    block3 = Conv2D(F2, (16, 1),\n",
    "                            data_format='channels_last',\n",
    "                            kernel_regularizer=L2(weightDecay),\n",
    "                            kernel_constraint = max_norm(maxNorm, axis=[0,1,2]),\n",
    "                            use_bias = False, padding = 'same')(block2)\n",
    "    block3 = BatchNormalization(axis = -1)(block3)\n",
    "    block3 = Activation('elu')(block3)\n",
    "    \n",
    "    block3 = AveragePooling2D((poolSize,1),data_format='channels_last')(block3)\n",
    "    block3 = Dropout(dropout)(block3)\n",
    "    return block3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. attention_block (Model.py  ------>  attention_models.py)\n",
    "\n",
    "attention_block takes dependancies from attention_module.py. This has three types of attention mechanisms used.\n",
    "1. Multihead Self Attention - mha_block\n",
    "2. Squeeze and Excitation Attention - se_block\n",
    "3. Covolutional Block Attention - cbam_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. mha_block. Best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention_LSA(tf.keras.layers.MultiHeadAttention):\n",
    "    \"\"\"local multi-head self attention block\n",
    "     \n",
    "     Locality Self Attention as described in https://arxiv.org/abs/2112.13492v1\n",
    "     This implementation is taken from  https://keras.io/examples/vision/vit_small_ds/ \n",
    "    \"\"\"    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # The trainable temperature term. The initial value is the square \n",
    "        # root of the key dimension.\n",
    "        self.tau = tf.Variable(math.sqrt(float(self._key_dim)), trainable=True)\n",
    "\n",
    "    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n",
    "        query = tf.multiply(query, 1.0 / self.tau)\n",
    "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
    "        attention_scores = self._masked_softmax(attention_scores, attention_mask)\n",
    "        attention_scores_dropout = self._dropout_layer(\n",
    "            attention_scores, training=training\n",
    "        )\n",
    "        attention_output = tf.einsum(\n",
    "            self._combine_equation, attention_scores_dropout, value\n",
    "        )\n",
    "        return attention_output, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mha_block(input_feature, key_dim=8, num_heads=2, dropout = 0.5, vanilla = True):\n",
    "    \"\"\"Multi Head self Attention (MHA) block.     \n",
    "       \n",
    "    Here we include two types of MHA blocks: \n",
    "            The original multi-head self-attention as described in https://arxiv.org/abs/1706.03762\n",
    "            The multi-head local self attention as described in https://arxiv.org/abs/2112.13492v1\n",
    "    \"\"\"    \n",
    "    # Layer normalization\n",
    "    x = LayerNormalization(epsilon=1e-6)(input_feature)\n",
    "    \n",
    "    if vanilla:\n",
    "        # Create a multi-head attention layer as described in \n",
    "        # 'Attention Is All You Need' https://arxiv.org/abs/1706.03762\n",
    "        x = MultiHeadAttention(key_dim = key_dim, num_heads = num_heads, dropout = dropout)(x, x)\n",
    "    else:\n",
    "        # Create a multi-head local self-attention layer as described in \n",
    "        # 'Vision Transformer for Small-Size Datasets' https://arxiv.org/abs/2112.13492v1\n",
    "        \n",
    "        # Build the diagonal attention mask\n",
    "        NUM_PATCHES = input_feature.shape[1]\n",
    "        diag_attn_mask = 1 - tf.eye(NUM_PATCHES)\n",
    "        diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)\n",
    "        \n",
    "        # Create a multi-head local self attention layer.\n",
    "        # x = MultiHeadAttention_LSA(key_dim = key_dim, num_heads = num_heads, dropout = dropout)(\n",
    "        #     x, x, attention_mask = diag_attn_mask)\n",
    "        x = MultiHeadAttention_LSA(key_dim = key_dim, num_heads = num_heads, dropout = dropout)(\n",
    "            x, x, attention_mask = diag_attn_mask)\n",
    "    x = Dropout(0.3)(x)\n",
    "    # Skip connection\n",
    "    mha_feature = Add()([input_feature, x])\n",
    "    \n",
    "    return mha_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. se_block (Squeeze and Excitation Block). Not need to be replicated since the best performance is from mha_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(input_feature, ratio=8, residual = False, apply_to_input=True):\n",
    "    \"\"\"Squeeze-and-Excitation(SE) block.\n",
    "    \n",
    "    As described in https://arxiv.org/abs/1709.01507\n",
    "    The implementation is taken from https://github.com/kobiso/CBAM-keras\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    se_feature = GlobalAveragePooling2D()(input_feature)\n",
    "    se_feature = Reshape((1, 1, channel))(se_feature)\n",
    "    assert se_feature.shape[1:] == (1,1,channel)\n",
    "    if (ratio != 0):\n",
    "        se_feature = Dense(channel // ratio,\n",
    "                           activation='relu',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           use_bias=True,\n",
    "                           bias_initializer='zeros')(se_feature)\n",
    "        assert se_feature.shape[1:] == (1,1,channel//ratio)\n",
    "    se_feature = Dense(channel,\n",
    "                       activation='sigmoid',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       use_bias=True,\n",
    "                       bias_initializer='zeros')(se_feature)\n",
    "    assert se_feature.shape[1:] == (1,1,channel)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se_feature = Permute((3, 1, 2))(se_feature)\n",
    "        \n",
    "    if(apply_to_input):\n",
    "        se_feature = multiply([input_feature, se_feature])\n",
    "    \n",
    "    # Residual Connection\n",
    "    if(residual): \n",
    "        se_feature = Add()([se_feature, input_feature])\n",
    "\n",
    "    return se_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. cbam_block (Convlusional Block Attention Module). Not need to be replicated since the best performance is from mha_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "    \n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)    \n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "        \n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "#     channel = input_feature._keras_shape[channel_axis]\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel//ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "    avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    \n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    \n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    \n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(input_feature, ratio=8, residual = False):\n",
    "    \"\"\" Convolutional Block Attention Module(CBAM) block.\n",
    "    \n",
    "    As described in https://arxiv.org/abs/1807.06521\n",
    "    The implementation is taken from https://github.com/kobiso/CBAM-keras\n",
    "    \"\"\"\n",
    "    \n",
    "    cbam_feature = channel_attention(input_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    \n",
    "    # Residual Connection\n",
    "    if(residual): \n",
    "        cbam_feature = Add()([input_feature, cbam_feature])\n",
    "\n",
    "    return cbam_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Attention_block that combines all three attention mechanisms into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(in_layer, attention_model, ratio=8, residual = False, apply_to_input=True): \n",
    "    in_sh = in_layer.shape # dimensions of the input tensor\n",
    "    in_len = len(in_sh) \n",
    "    expanded_axis = 2 # defualt = 2\n",
    "    \n",
    "    if attention_model == 'mha':   # Multi-head self attention layer \n",
    "        if(in_len > 3):\n",
    "            in_layer = Reshape((in_sh[1],-1))(in_layer)\n",
    "        out_layer = mha_block(in_layer)\n",
    "    elif attention_model == 'mhla':  # Multi-head local self-attention layer \n",
    "        if(in_len > 3):\n",
    "            in_layer = Reshape((in_sh[1],-1))(in_layer)\n",
    "        out_layer = mha_block(in_layer, vanilla = False)\n",
    "    elif attention_model == 'se':   # Squeeze-and-excitation layer\n",
    "        if(in_len < 4):\n",
    "            in_layer = tf.expand_dims(in_layer, axis=expanded_axis)\n",
    "        out_layer = se_block(in_layer, ratio, residual, apply_to_input)\n",
    "    elif attention_model == 'cbam': # Convolutional block attention module\n",
    "        if(in_len < 4):\n",
    "            in_layer = tf.expand_dims(in_layer, axis=expanded_axis)\n",
    "        out_layer = cbam_block(in_layer, ratio=ratio, residual = residual)\n",
    "    else:\n",
    "        raise Exception(\"'{}' is not supported attention module!\".format(attention_model))\n",
    "        \n",
    "    if (in_len == 3 and len(out_layer.shape) == 4):\n",
    "        out_layer = tf.squeeze(out_layer, expanded_axis)\n",
    "    elif (in_len == 4 and len(out_layer.shape) == 3):\n",
    "        out_layer = Reshape((in_sh[1], in_sh[2], in_sh[3]))(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. TCN_block (Models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCN_block_(input_layer,input_dimension,depth,kernel_size,filters, dropout,\n",
    "               weightDecay = 0.009, maxNorm = 0.6, activation='relu'):\n",
    "    \"\"\" TCN_block from Bai et al 2018\n",
    "        Temporal Convolutional Network (TCN)\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        using different regularization methods\n",
    "    \"\"\"    \n",
    "    \n",
    "    block = Conv1D(filters, kernel_size=kernel_size, dilation_rate=1, activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "                    \n",
    "                    padding = 'causal',kernel_initializer='he_uniform')(input_layer)\n",
    "    block = BatchNormalization()(block)\n",
    "    block = Activation(activation)(block)\n",
    "    block = Dropout(dropout)(block)\n",
    "    block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=1,activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "\n",
    "                    padding = 'causal',kernel_initializer='he_uniform')(block)\n",
    "    block = BatchNormalization()(block)\n",
    "    block = Activation(activation)(block)\n",
    "    block = Dropout(dropout)(block)\n",
    "    if(input_dimension != filters):\n",
    "        conv = Conv1D(filters,kernel_size=1,\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "                      \n",
    "                    padding='same')(input_layer)\n",
    "        added = Add()([block,conv])\n",
    "    else:\n",
    "        added = Add()([block,input_layer])\n",
    "    out = Activation(activation)(added)\n",
    "    \n",
    "    for i in range(depth-1):\n",
    "        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "                    \n",
    "                   padding = 'causal',kernel_initializer='he_uniform')(out)\n",
    "        block = BatchNormalization()(block)\n",
    "        block = Activation(activation)(block)\n",
    "        block = Dropout(dropout)(block)\n",
    "        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "\n",
    "                    padding = 'causal',kernel_initializer='he_uniform')(block)\n",
    "        block = BatchNormalization()(block)\n",
    "        block = Activation(activation)(block)\n",
    "        block = Dropout(dropout)(block)\n",
    "        added = Add()([block, out])\n",
    "        out = Activation(activation)(added)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. ATCNet architecture that uses Conv_block, attention_block and TCN_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATCNet_(n_classes, in_chans = 22, in_samples = 1125, n_windows = 5, attention = 'mha', \n",
    "           eegn_F1 = 16, eegn_D = 2, eegn_kernelSize = 64, eegn_poolSize = 7, eegn_dropout=0.3, \n",
    "           tcn_depth = 2, tcn_kernelSize = 4, tcn_filters = 32, tcn_dropout = 0.3, \n",
    "           tcn_activation = 'elu', fuse = 'average'):\n",
    "    \n",
    "    \"\"\" ATCNet model from Altaheri et al 2023.\n",
    "        See details at https://ieeexplore.ieee.org/abstract/document/9852687\n",
    "    \n",
    "        Notes\n",
    "        -----\n",
    "        The initial values in this model are based on the values identified by\n",
    "        the authors\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        .. H. Altaheri, G. Muhammad, and M. Alsulaiman. \"Physics-informed \n",
    "           attention temporal convolutional network for EEG-based motor imagery \n",
    "           classification.\" IEEE Transactions on Industrial Informatics, \n",
    "           vol. 19, no. 2, pp. 2249-2258, (2023) \n",
    "           https://doi.org/10.1109/TII.2022.3197419\n",
    "    \"\"\"\n",
    "    input_1 = Input(shape = (1,in_chans, in_samples))   #     TensorShape([None, 1, 22, 1125])\n",
    "    input_2 = Permute((3,2,1))(input_1) \n",
    "\n",
    "    dense_weightDecay = 0.5  \n",
    "    conv_weightDecay = 0.009\n",
    "    conv_maxNorm = 0.6\n",
    "    from_logits = False\n",
    "\n",
    "    numFilters = eegn_F1\n",
    "    F2 = numFilters*eegn_D\n",
    "\n",
    "    block1 = Conv_block_(input_layer = input_2, F1 = eegn_F1, D = eegn_D, \n",
    "                        kernLength = eegn_kernelSize, poolSize = eegn_poolSize,\n",
    "                        weightDecay = conv_weightDecay, maxNorm = conv_maxNorm,\n",
    "                        in_chans = in_chans, dropout = eegn_dropout)\n",
    "    block1 = Lambda(lambda x: x[:,:,-1,:])(block1)\n",
    "       \n",
    "    # Sliding window \n",
    "    sw_concat = []   # to store concatenated or averaged sliding window outputs\n",
    "    for i in range(n_windows):\n",
    "        st = i\n",
    "        end = block1.shape[1]-n_windows+i+1\n",
    "        block2 = block1[:, st:end, :]\n",
    "        \n",
    "        # Attention_model\n",
    "        if attention is not None:\n",
    "            if (attention == 'se' or attention == 'cbam'):\n",
    "                block2 = Permute((2, 1))(block2) # shape=(None, 32, 16)\n",
    "                block2 = attention_block(block2, attention)\n",
    "                block2 = Permute((2, 1))(block2) # shape=(None, 16, 32)\n",
    "            else: block2 = attention_block(block2, attention)\n",
    "\n",
    "        # Temporal convolutional network (TCN)\n",
    "        block3 = TCN_block_(input_layer = block2, input_dimension = F2, depth = tcn_depth,\n",
    "                            kernel_size = tcn_kernelSize, filters = tcn_filters, \n",
    "                            weightDecay = conv_weightDecay, maxNorm = conv_maxNorm,\n",
    "                            dropout = tcn_dropout, activation = tcn_activation)\n",
    "        # Get feature maps of the last sequence\n",
    "        block3 = Lambda(lambda x: x[:,-1,:])(block3)\n",
    "        \n",
    "        # Outputs of sliding window: Average_after_dense or concatenate_then_dense\n",
    "        if(fuse == 'average'):\n",
    "            sw_concat.append(Dense(n_classes, kernel_regularizer=L2(dense_weightDecay))(block3))\n",
    "        elif(fuse == 'concat'):\n",
    "            if i == 0:\n",
    "                sw_concat = block3\n",
    "            else:\n",
    "                sw_concat = Concatenate()([sw_concat, block3])\n",
    "                \n",
    "    if(fuse == 'average'):\n",
    "        if len(sw_concat) > 1: # more than one window\n",
    "            sw_concat = tf.keras.layers.Average()(sw_concat[:])\n",
    "        else: # one window (# windows = 1)\n",
    "            sw_concat = sw_concat[0]\n",
    "    elif(fuse == 'concat'):\n",
    "        sw_concat = Dense(n_classes, kernel_regularizer=L2(dense_weightDecay))(sw_concat)\n",
    "               \n",
    "    if from_logits:  # No activation here because we are using from_logits=True\n",
    "        out = Activation('linear', name = 'linear')(sw_concat)\n",
    "    else:   # Using softmax activation\n",
    "        out = Activation('softmax', name = 'softmax')(sw_concat)\n",
    "       \n",
    "    return Model(inputs = input_1, outputs = out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Selecting Which Model to Run  \n",
    "\n",
    "This does not matter to us if we are only looking to run ATCNet Model. The additional models are commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name, dataset_conf, from_logits = False):\n",
    "    \n",
    "    n_classes = dataset_conf.get('n_classes')\n",
    "    n_channels = dataset_conf.get('n_channels')\n",
    "    in_samples = dataset_conf.get('in_samples')\n",
    "\n",
    "    # Select the model\n",
    "    if(model_name == 'ATCNet'):\n",
    "        # Train using the proposed ATCNet model: https://ieeexplore.ieee.org/document/9852687\n",
    "        model = ATCNet_( \n",
    "            # Dataset parameters\n",
    "            n_classes = n_classes, \n",
    "            in_chans = n_channels, \n",
    "            in_samples = in_samples, \n",
    "            # Sliding window (SW) parameter\n",
    "            n_windows = 5, \n",
    "            # Attention (AT) block parameter\n",
    "            attention = 'mha', # Options: None, 'mha','mhla', 'cbam', 'se'\n",
    "            # Convolutional (CV) block parameters\n",
    "            eegn_F1 = 16,\n",
    "            eegn_D = 2, \n",
    "            eegn_kernelSize = 64,\n",
    "            eegn_poolSize = 7,\n",
    "            eegn_dropout = 0.3,\n",
    "            # Temporal convolutional (TC) block parameters\n",
    "            tcn_depth = 2, \n",
    "            tcn_kernelSize = 4,\n",
    "            tcn_filters = 32,\n",
    "            tcn_dropout = 0.3, \n",
    "            tcn_activation='elu',\n",
    "            )     \n",
    "    # elif(model_name == 'TCNet_Fusion'):\n",
    "    #     # Train using TCNet_Fusion: https://doi.org/10.1016/j.bspc.2021.102826\n",
    "    #     model = models.TCNet_Fusion(n_classes = n_classes, Chans=n_channels, Samples=in_samples)      \n",
    "    # elif(model_name == 'EEGTCNet'):\n",
    "    #     # Train using EEGTCNet: https://arxiv.org/abs/2006.00622\n",
    "    #     model = models.EEGTCNet(n_classes = n_classes, Chans=n_channels, Samples=in_samples)          \n",
    "    # elif(model_name == 'EEGNet'):\n",
    "    #     # Train using EEGNet: https://arxiv.org/abs/1611.08024\n",
    "    #     model = models.EEGNet_classifier(n_classes = n_classes, Chans=n_channels, Samples=in_samples) \n",
    "    # elif(model_name == 'EEGNeX'):\n",
    "    #     # Train using EEGNeX: https://arxiv.org/abs/2207.12369\n",
    "    #     model = models.EEGNeX_8_32(n_timesteps = in_samples , n_features = n_channels, n_outputs = n_classes)\n",
    "    # elif(model_name == 'DeepConvNet'):\n",
    "    #     # Train using DeepConvNet: https://doi.org/10.1002/hbm.23730\n",
    "    #     model = models.DeepConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "    # elif(model_name == 'ShallowConvNet'):\n",
    "    #     # Train using ShallowConvNet: https://doi.org/10.1002/hbm.23730\n",
    "    #     model = models.ShallowConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "    # elif(model_name == 'MBEEG_SENet'):\n",
    "    #     # Train using MBEEG_SENet: https://www.mdpi.com/2075-4418/12/4/995\n",
    "    #     model = models.MBEEG_SENet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"'{}' model is not supported yet!\".format(model_name))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Drawing Curves for the Learning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_learning_curves(history, sub):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy - subject: ' + str(sub))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss - subject: ' + str(sub))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset_conf, train_conf, results_path):\n",
    "    \n",
    "    # remove the 'result' folder before training\n",
    "    if os.path.exists(results_path):\n",
    "        # Remove the folder and its contents\n",
    "        shutil.rmtree(results_path)\n",
    "        os.makedirs(results_path)        \n",
    "\n",
    "    # Get the current 'IN' time to calculate the overall training time\n",
    "    in_exp = time.time()\n",
    "    # Create a file to store the path of the best model among several runs\n",
    "    best_models = open(results_path + \"/best models.txt\", \"w\")\n",
    "    # Create a file to store performance during training\n",
    "    log_write = open(results_path + \"/log.txt\", \"w\")\n",
    "    \n",
    "    # Get dataset paramters\n",
    "    dataset = dataset_conf.get('name')\n",
    "    n_sub = dataset_conf.get('n_sub')\n",
    "    data_path = dataset_conf.get('data_path')\n",
    "    isStandard = dataset_conf.get('isStandard')\n",
    "    LOSO = dataset_conf.get('LOSO')\n",
    "    # Get training hyperparamters\n",
    "    batch_size = train_conf.get('batch_size')\n",
    "    epochs = train_conf.get('epochs')\n",
    "    patience = train_conf.get('patience')\n",
    "    lr = train_conf.get('lr')\n",
    "    LearnCurves = train_conf.get('LearnCurves') # Plot Learning Curves?\n",
    "    n_train = train_conf.get('n_train')\n",
    "    model_name = train_conf.get('model')\n",
    "    from_logits = train_conf.get('from_logits') \n",
    "\n",
    "    # Initialize variables\n",
    "    acc = np.zeros((n_sub, n_train))\n",
    "    kappa = np.zeros((n_sub, n_train))\n",
    "    \n",
    "    # Iteration over subjects \n",
    "    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "\n",
    "        print('\\nTraining on subject ', sub+1)\n",
    "        log_write.write( '\\nTraining on subject '+ str(sub+1) +'\\n')\n",
    "        # Initiating variables to save the best subject accuracy among multiple runs.\n",
    "        BestSubjAcc = 0 \n",
    "        bestTrainingHistory = [] \n",
    "        \n",
    "        # Get training and test data\n",
    "        X_train, _, y_train_onehot, _, _, _ = get_data(\n",
    "            data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n",
    "         \n",
    "        # Divide the training data into training and validation\n",
    "        X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_train, y_train_onehot, test_size=0.2, random_state=42)       \n",
    "        \n",
    "        # Iteration over multiple runs \n",
    "        for train in range(n_train): # How many repetitions of training for subject i.\n",
    "            # Set the random seed for TensorFlow and NumPy random number generator. \n",
    "            # The purpose of setting a seed is to ensure reproducibility in random operations. \n",
    "            tf.random.set_seed(train+1)\n",
    "            np.random.seed(train+1)\n",
    "            \n",
    "            # Get the current 'IN' time to calculate the 'run' training time\n",
    "            in_run = time.time()\n",
    "            \n",
    "            # Create folders and files to save trained models for all runs\n",
    "            filepath = results_path + '/saved models/run-{}'.format(train+1)\n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)        \n",
    "            filepath = filepath + '/subject-{}.h5'.format(sub+1)\n",
    "            \n",
    "            # Create the model\n",
    "            model = getModel(model_name, dataset_conf, from_logits)\n",
    "            # Compile and train the model\n",
    "            model.compile(loss=CategoricalCrossentropy(from_logits=from_logits), optimizer=Adam(learning_rate=lr), metrics=['accuracy'])          \n",
    "\n",
    "            # model.summary()\n",
    "            # plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                                save_best_only=True, save_weights_only=True, mode='min'),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.90, patience=20, verbose=0, min_lr=0.0001),  \n",
    "                # EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\n",
    "            ]\n",
    "            history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), \n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=0)\n",
    "           \n",
    "            # Evaluate the performance of the trained model based on the validation data\n",
    "            # Here we load the Trained weights from the file saved in the hard \n",
    "            # disk, which should be the same as the weights of the current model.\n",
    "            model.load_weights(filepath)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            if from_logits:\n",
    "                y_pred = tf.nn.softmax(y_pred).numpy().argmax(axis=-1)\n",
    "            else:\n",
    "                y_pred = y_pred.argmax(axis=-1)\n",
    "                \n",
    "            labels = y_val_onehot.argmax(axis=-1)\n",
    "            acc[sub, train]  = accuracy_score(labels, y_pred)\n",
    "            kappa[sub, train] = cohen_kappa_score(labels, y_pred)\n",
    "                        \n",
    "            # Get the current 'OUT' time to calculate the 'run' training time\n",
    "            out_run = time.time()\n",
    "            # Print & write performance measures for each run\n",
    "            info = 'Subject: {}   seed {}   time: {:.1f} m   '.format(sub+1, train+1, ((out_run-in_run)/60))\n",
    "            info = info + 'valid_acc: {:.4f}   valid_loss: {:.3f}'.format(acc[sub, train], min(history.history['val_loss']))\n",
    "            print(info)\n",
    "            log_write.write(info +'\\n')\n",
    "            # If current training run is better than previous runs, save the history.\n",
    "            if(BestSubjAcc < acc[sub, train]):\n",
    "                 BestSubjAcc = acc[sub, train]\n",
    "                 bestTrainingHistory = history\n",
    "        \n",
    "        # Store the path of the best model among several runs\n",
    "        best_run = np.argmax(acc[sub,:])\n",
    "        filepath = '/saved models/run-{}/subject-{}.h5'.format(best_run+1, sub+1)+'\\n'\n",
    "        best_models.write(filepath)\n",
    "\n",
    "        # Plot Learning curves \n",
    "        if (LearnCurves == True):\n",
    "            print('Plot Learning Curves ....... ')\n",
    "            draw_learning_curves(bestTrainingHistory, sub+1)\n",
    "          \n",
    "    # Get the current 'OUT' time to calculate the overall training time\n",
    "    out_exp = time.time()\n",
    "           \n",
    "    # Print & write the validation performance using all seeds\n",
    "    head1 = head2 = '         '\n",
    "    for sub in range(n_sub): \n",
    "        head1 = head1 + 'sub_{}   '.format(sub+1)\n",
    "        head2 = head2 + '-----   '\n",
    "    head1 = head1 + '  average'\n",
    "    head2 = head2 + '  -------'\n",
    "    info = '\\n---------------------------------\\nValidation performance (acc %):'\n",
    "    info = info + '\\n---------------------------------\\n' + head1 +'\\n'+ head2\n",
    "    for run in range(n_train): \n",
    "        info = info + '\\nSeed {}:  '.format(run+1)\n",
    "        for sub in range(n_sub): \n",
    "            info = info + '{:.2f}   '.format(acc[sub, run]*100)\n",
    "        info = info + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n",
    "    info = info + '\\n---------------------------------\\nAverage acc - all seeds: '\n",
    "    info = info + '{:.2f} %\\n\\nTrain Time  - all seeds: {:.1f}'.format(np.average(acc)*100, (out_exp-in_exp)/(60))\n",
    "    info = info + ' min\\n---------------------------------\\n'\n",
    "    print(info)\n",
    "    log_write.write(info+'\\n')\n",
    "\n",
    "    # Close open files \n",
    "    best_models.close()   \n",
    "    log_write.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on subject  1\n",
      "/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/datasets1/A01T.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/datasets1/A01T.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m train_conf \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_train\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     45\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCurves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_logits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATCNet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#Train the model\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset_conf, train_conf, results_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_path)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Get training and test data\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m X_train, _, y_train_onehot, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOSO\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLOSO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misStandard\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43misStandard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Divide the training data into training and validation\u001b[39;00m\n\u001b[1;32m     53\u001b[0m X_train, X_val, y_train_onehot, y_val_onehot \u001b[38;5;241m=\u001b[39m train_test_split(X_train, y_train_onehot, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)       \n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(path, subject, dataset, classes_labels, LOSO, isStandard, isShuffle)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBCI2a\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     16\u001b[0m     path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subject\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_BCI2a_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     X_test, y_test \u001b[38;5;241m=\u001b[39m load_BCI2a_data(path, subject\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCS2R\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mload_BCI2a_data\u001b[0;34m(data_path, subject, training, all_trials)\u001b[0m\n\u001b[1;32m     37\u001b[0m NO_valid_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m---> 39\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     a \u001b[38;5;241m=\u001b[39m sio\u001b[38;5;241m.\u001b[39mloadmat(data_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(subject)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/datasets1/A01T.mat'"
     ]
    }
   ],
   "source": [
    "# Define dataset parameters\n",
    "dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n",
    "\n",
    "if dataset == 'BCI2a': \n",
    "    in_samples = 1125\n",
    "    n_channels = 22\n",
    "    n_sub = 9\n",
    "    n_classes = 4\n",
    "    classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
    "    #data_path = os.path.expanduser('~') + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n",
    "    data_path = os.path.expanduser('~') + '/Mac/Codes/FYP_Codes/BCI-Competition-IV/dataset'\n",
    "\n",
    "# elif dataset == 'HGD': \n",
    "#     in_samples = 1125\n",
    "#     n_channels = 44\n",
    "#     n_sub = 14\n",
    "#     n_classes = 4\n",
    "#     classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']     \n",
    "#     data_path = os.path.expanduser('~') + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n",
    "# elif dataset == 'CS2R': \n",
    "#     in_samples = 1125\n",
    "#     # in_samples = 576\n",
    "#     n_channels = 32\n",
    "#     n_sub = 18\n",
    "#     n_classes = 3\n",
    "#     # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']     \n",
    "#     classes_labels = ['Fingers', 'Wrist','Elbow']     \n",
    "#     # classes_labels = ['Fingers', 'Elbow']     \n",
    "#     data_path = os.path.expanduser('~') + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n",
    "else:\n",
    "    raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "    \n",
    "# Create a folder to store the results of the experiment\n",
    "results_path = os.getcwd() + \"/results\"\n",
    "if not  os.path.exists(results_path):\n",
    "    os.makedirs(results_path)   # Create a new directory if it does not exist \n",
    "    \n",
    "# Set dataset paramters \n",
    "dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n",
    "                'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n",
    "                'data_path': data_path, 'isStandard': True, 'LOSO': False}\n",
    "\n",
    "# Set training hyperparamters\n",
    "train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n",
    "                'LearnCurves': True, 'from_logits': False, 'model':'ATCNet'}\n",
    "\n",
    "#Train the model\n",
    "train(dataset_conf, train_conf, results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
