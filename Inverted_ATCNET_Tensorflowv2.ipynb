{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil \n",
    "import time \n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.io import read_raw_edf\n",
    "from dateutil.parser import parse \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.regularizers import L2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, Activation, AveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv1D, Conv2D, SeparableConv2D, DepthwiseConv2D, MultiHeadAttention\n",
    "from keras.layers import BatchNormalization, LayerNormalization, Flatten\n",
    "from keras.layers import Add, multiply, Concatenate, Lambda, Input, Permute, Reshape\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two datasets are used for the training and testing. The second dataset might not be required for the ATCNet model and might be used only for other models.\n",
    "1. BCI Competition IV 2a\n",
    "2. CS2R Dataset V2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. BCI Competition IV 2a Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_BCI2a_data(data_path, subject, training, all_trials = True):\n",
    "    \"\"\" Loading and Dividing of the data set based on the subject-specific \n",
    "    (subject-dependent) approach.\n",
    "    In this approach, we used the same training and testing dataas the original\n",
    "    competition, i.e., 288 x 9 trials in session 1 for training, \n",
    "    and 288 x 9 trials in session 2 for testing.  \n",
    "   \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string\n",
    "            dataset path\n",
    "            # Dataset BCI Competition IV-2a is available on \n",
    "            # http://bnci-horizon-2020.eu/database/data-sets\n",
    "        subject: int\n",
    "            number of subject in [1, .. ,9]\n",
    "        training: bool\n",
    "            if True, load training data\n",
    "            if False, load testing data\n",
    "        all_trials: bool\n",
    "            if True, load all trials\n",
    "            if False, ignore trials with artifacts \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define MI-trials parameters\n",
    "    n_channels = 22\n",
    "    n_tests = 6*48     \n",
    "    window_Length = 7*250 \n",
    "    \n",
    "    # Define MI trial window \n",
    "    fs = 250          # sampling rate\n",
    "    t1 = int(1.5*fs)  # start time_point\n",
    "    t2 = int(6*fs)    # end time_point\n",
    "\n",
    "    class_return = np.zeros(n_tests)\n",
    "    data_return = np.zeros((n_tests, n_channels, window_Length))\n",
    "\n",
    "    NO_valid_trial = 0\n",
    "    if training:\n",
    "        a = sio.loadmat(data_path+'A0'+str(subject)+'T.mat')\n",
    "    else:\n",
    "        a = sio.loadmat(data_path+'A0'+str(subject)+'E.mat')\n",
    "    a_data = a['data']\n",
    "    for ii in range(0,a_data.size):\n",
    "        a_data1 = a_data[0,ii]\n",
    "        a_data2= [a_data1[0,0]]\n",
    "        a_data3= a_data2[0]\n",
    "        a_X         = a_data3[0]\n",
    "        a_trial     = a_data3[1]\n",
    "        a_y         = a_data3[2]\n",
    "        a_artifacts = a_data3[5]\n",
    "\n",
    "        for trial in range(0,a_trial.size):\n",
    "             if(a_artifacts[trial] != 0 and not all_trials):\n",
    "                 continue\n",
    "             data_return[NO_valid_trial,:,:] = np.transpose(a_X[int(a_trial[trial]):(int(a_trial[trial])+window_Length),:22])\n",
    "             class_return[NO_valid_trial] = int(a_y[trial])\n",
    "             NO_valid_trial +=1        \n",
    "    \n",
    "\n",
    "    data_return = data_return[0:NO_valid_trial, :, t1:t2]\n",
    "    class_return = class_return[0:NO_valid_trial]\n",
    "    class_return = (class_return-1).astype(int)\n",
    "\n",
    "    return data_return, class_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Loading CS2R Dataset v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CS2R_data_v2(data_path, subject, training, \n",
    "                      classes_labels =  ['Fingers', 'Wrist','Elbow','Rest'], \n",
    "                      all_trials = True):\n",
    "    \"\"\" Loading training/testing data for the CS2R motor imagery dataset\n",
    "    for a specific subject        \n",
    "   \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string\n",
    "            dataset path\n",
    "        subject: int\n",
    "            number of subject in [1, .. ,9]\n",
    "        training: bool\n",
    "            if True, load training data\n",
    "            if False, load testing data\n",
    "        classes_labels: tuple\n",
    "            classes of motor imagery returned by the method (default: all) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all subjects files with .edf format.\n",
    "    subjectFiles = glob.glob(data_path + 'S_*/')\n",
    "    \n",
    "    # Get all subjects numbers sorted without duplicates.\n",
    "    subjectNo = list(dict.fromkeys(sorted([x[len(x)-4:len(x)-1] for x in subjectFiles])))\n",
    "    # print(SubjectNo[subject].zfill(3))\n",
    "    \n",
    "    if training:  session = 1\n",
    "    else:         session = 2\n",
    "    \n",
    "    num_runs = 5\n",
    "    sfreq = 250 #250\n",
    "    mi_duration = 4.5 #4.5\n",
    "\n",
    "    data = np.zeros([num_runs*51, 32, int(mi_duration*sfreq)])\n",
    "    classes = np.zeros(num_runs * 51)\n",
    "    valid_trails = 0\n",
    "    \n",
    "    onset = np.zeros([num_runs, 51])\n",
    "    duration = np.zeros([num_runs, 51])\n",
    "    description = np.zeros([num_runs, 51])\n",
    "\n",
    "    #Loop to the first 4 runs.\n",
    "    CheckFiles = glob.glob(data_path + 'S_' + subjectNo[subject].zfill(3) + '/S' + str(session) + '/*.edf')\n",
    "    if not CheckFiles:\n",
    "        return \n",
    "    \n",
    "    for runNo in range(num_runs): \n",
    "        valid_trails_in_run = 0\n",
    "        #Get .edf and .json file for following subject and run.\n",
    "        EDFfile = glob.glob(data_path + 'S_' + subjectNo[subject].zfill(3) + '/S' + str(session) + '/S_'+subjectNo[subject].zfill(3)+'_'+str(session)+str(runNo+1)+'*.edf')\n",
    "        JSONfile = glob.glob(data_path + 'S_'+subjectNo[subject].zfill(3) + '/S'+ str(session) +'/S_'+subjectNo[subject].zfill(3)+'_'+str(session)+str(runNo+1)+'*.json')\n",
    "    \n",
    "        #Check if EDFfile list is empty\n",
    "        if not EDFfile:\n",
    "          continue\n",
    "    \n",
    "        # We use mne.read_raw_edf to read in the .edf EEG files\n",
    "        raw = read_raw_edf(str(EDFfile[0]), preload=True, verbose=False)\n",
    "        \n",
    "        # Opening JSON file of the current RUN.\n",
    "        f = open(JSONfile[0],) \n",
    "    \n",
    "        # returns JSON object as a dictionary \n",
    "        JSON = json.load(f) \n",
    "    \n",
    "        #Number of Keystrokes Markers\n",
    "        keyStrokes = np.min([len(JSON['Markers']), 51]) #len(JSON['Markers']), to avoid extra markers by accident\n",
    "        # MarkerStart = JSON['Markers'][0]['startDatetime']\n",
    "           \n",
    "        #Get Start time of marker\n",
    "        date_string = EDFfile[0][-21:-4]\n",
    "        datetime_format = \"%d.%m.%y_%H.%M.%S\"\n",
    "        startRecordTime = datetime.strptime(date_string, datetime_format).astimezone()\n",
    "    \n",
    "        currentTrialNo = 0 # 1 = fingers, 2 = Wrist, 3 = Elbow, 4 = rest\n",
    "        if(runNo == 4): \n",
    "            currentTrialNo = 4\n",
    "    \n",
    "        ch_names = raw.info['ch_names'][4:36]\n",
    "             \n",
    "        # filter the data \n",
    "        raw.filter(4., 50., fir_design='firwin')  \n",
    "        \n",
    "        raw = raw.copy().pick_channels(ch_names = ch_names)\n",
    "        raw = raw.copy().resample(sfreq = sfreq)\n",
    "        fs = raw.info['sfreq']\n",
    "\n",
    "        for trail in range(keyStrokes):\n",
    "            \n",
    "            # class for current trial\n",
    "            if(runNo == 4 ):               # In Run 5 all trials are 'reset'\n",
    "                currentTrialNo = 4\n",
    "            elif (currentTrialNo == 3):    # Set the class of current trial to 1 'Fingers'\n",
    "                currentTrialNo = 1   \n",
    "            else:                          # In Runs 1-4, 1st trial is 1 'Fingers', 2nd trial is 2 'Wrist', and 3rd trial is 'Elbow', and repeat ('Fingers', 'Wrist', 'Elbow', ..)\n",
    "                currentTrialNo = currentTrialNo + 1\n",
    "                \n",
    "            trailDuration = 8\n",
    "            \n",
    "            trailTime = parse(JSON['Markers'][trail]['startDatetime'])\n",
    "            trailStart = trailTime - startRecordTime\n",
    "            trailStart = trailStart.seconds \n",
    "            start = trailStart + (6 - mi_duration)\n",
    "            stop = trailStart + 6\n",
    "\n",
    "            if (trail < keyStrokes-1):\n",
    "                trailDuration = parse(JSON['Markers'][trail+1]['startDatetime']) - parse(JSON['Markers'][trail]['startDatetime'])\n",
    "                trailDuration =  trailDuration.seconds + (trailDuration.microseconds/1000000)\n",
    "                if (trailDuration < 7.5) or (trailDuration > 8.5):\n",
    "                    print('In Session: {} - Run: {}, Trail no: {} is skipped due to short/long duration of: {:.2f}'.format(session, (runNo+1), (trail+1), trailDuration))\n",
    "                    if (trailDuration > 14 and trailDuration < 18):\n",
    "                        if (currentTrialNo == 3):   currentTrialNo = 1   \n",
    "                        else:                       currentTrialNo = currentTrialNo + 1\n",
    "                    continue\n",
    "                \n",
    "            elif (trail == keyStrokes-1):\n",
    "                trailDuration = raw[0, int(trailStart*int(fs)):int((trailStart+8)*int(fs))][0].shape[1]/fs\n",
    "                if (trailDuration < 7.8) :\n",
    "                    print('In Session: {} - Run: {}, Trail no: {} is skipped due to short/long duration of: {:.2f}'.format(session, (runNo+1), (trail+1), trailDuration))\n",
    "                    continue\n",
    "\n",
    "            MITrail = raw[:32, int(start*int(fs)):int(stop*int(fs))][0]\n",
    "            if (MITrail.shape[1] != data.shape[2]):\n",
    "                print('Error in Session: {} - Run: {}, Trail no: {} due to the lost of data'.format(session, (runNo+1), (trail+1)))\n",
    "                return\n",
    "            \n",
    "            # select some specific classes\n",
    "            if ((('Fingers' in classes_labels) and (currentTrialNo==1)) or \n",
    "            (('Wrist' in classes_labels) and (currentTrialNo==2)) or \n",
    "            (('Elbow' in classes_labels) and (currentTrialNo==3)) or \n",
    "            (('Rest' in classes_labels) and (currentTrialNo==4))):\n",
    "                data[valid_trails] = MITrail\n",
    "                classes[valid_trails] =  currentTrialNo\n",
    "                \n",
    "                # For Annotations\n",
    "                onset[runNo, valid_trails_in_run]  = start\n",
    "                duration[runNo, valid_trails_in_run] = trailDuration - (6 - mi_duration)\n",
    "                description[runNo, valid_trails_in_run] = currentTrialNo\n",
    "                valid_trails += 1\n",
    "                valid_trails_in_run += 1\n",
    "                         \n",
    "    data = data[0:valid_trails, :, :]\n",
    "    classes = classes[0:valid_trails]\n",
    "    classes = (classes-1).astype(int)\n",
    "\n",
    "    return data, classes, onset, duration, description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. LOSO (Leave One Subject Out)  \n",
    "\n",
    "This loads one of the datasets out of the above two and seprate the (X_train, y_train, X_test, y_test) using the LOSO method. This is applicable during the subject independat training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_LOSO (data_path, subject, dataset): \n",
    "    \"\"\" Loading and Dividing of the data set based on the \n",
    "    'Leave One Subject Out' (LOSO) evaluation approach. \n",
    "    LOSO is used for  Subject-independent evaluation.\n",
    "    In LOSO, the model is trained and evaluated by several folds, equal to the \n",
    "    number of subjects, and for each fold, one subject is used for evaluation\n",
    "    and the others for training. The LOSO evaluation technique ensures that \n",
    "    separate subjects (not visible in the training data) are usedto evaluate \n",
    "    the model.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string\n",
    "            dataset path\n",
    "            # Dataset BCI Competition IV-2a is available at \n",
    "            # http://bnci-horizon-2020.eu/database/data-sets\n",
    "        subject: int\n",
    "            number of subject in [1, .. ,9/14]\n",
    "            Here, the subject data is used  test the model and other subjects data\n",
    "            for training\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, y_train = [], []\n",
    "    for sub in range (0,9):\n",
    "        path = data_path+'s' + str(sub+1) + '/'\n",
    "        \n",
    "        if (dataset == 'BCI2a'):\n",
    "            X1, y1 = load_BCI2a_data(path, sub+1, True)\n",
    "            X2, y2 = load_BCI2a_data(path, sub+1, False)\n",
    "        elif (dataset == 'CS2R'):\n",
    "            X1, y1, _, _, _  = load_CS2R_data_v2(path, sub, True)\n",
    "            X2, y2, _, _, _  = load_CS2R_data_v2(path, sub, False)\n",
    "        # elif (dataset == 'HGD'):\n",
    "        #     X1, y1 = load_HGD_data(path, sub+1, True)\n",
    "        #     X2, y2 = load_HGD_data(path, sub+1, False)\n",
    "        \n",
    "        X = np.concatenate((X1, X2), axis=0)\n",
    "        y = np.concatenate((y1, y2), axis=0)\n",
    "                   \n",
    "        if (sub == subject):\n",
    "            X_test = X\n",
    "            y_test = y\n",
    "        elif (X_train == []):\n",
    "            X_train = X\n",
    "            y_train = y\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X), axis=0)\n",
    "            y_train = np.concatenate((y_train, y), axis=0)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Standardizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(X_train, X_test, channels): \n",
    "    # X_train & X_test :[Trials, MI-tasks, Channels, Time points]\n",
    "    for j in range(channels):\n",
    "          scaler = StandardScaler()\n",
    "          scaler.fit(X_train[:, 0, j, :])\n",
    "          X_train[:, 0, j, :] = scaler.transform(X_train[:, 0, j, :])\n",
    "          X_test[:, 0, j, :] = scaler.transform(X_test[:, 0, j, :])\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. get_data  \n",
    "\n",
    "This combines the data loading and preprocessing methods into one function. \n",
    "\n",
    "If the method is subject independant then LOSO should not be used. \n",
    "\n",
    "For such cases, Train/Test Split is handled within this funciton. In such subject specific method is used, the train and split is done to each subject seperately. This split is done as it was done in BCI Competition IV dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, subject, dataset = 'BCI2a', classes_labels = 'all', LOSO = False, isStandard = True, isShuffle = True):\n",
    "    \n",
    "    # Load and split the dataset into training and testing \n",
    "    if LOSO:\n",
    "        \"\"\" Loading and Dividing of the dataset based on the \n",
    "        'Leave One Subject Out' (LOSO) evaluation approach. \"\"\" \n",
    "        X_train, y_train, X_test, y_test = load_data_LOSO(path, subject, dataset)\n",
    "    else:\n",
    "        \"\"\" Loading and Dividing of the data set based on the subject-specific \n",
    "        (subject-dependent) approach.\n",
    "        In this approach, we used the same training and testing data as the original\n",
    "        competition, i.e., for BCI Competition IV-2a, 288 x 9 trials in session 1 \n",
    "        for training, and 288 x 9 trials in session 2 for testing.  \n",
    "        \"\"\"\n",
    "        if (dataset == 'BCI2a'):\n",
    "            path = path + 's{:}/'.format(subject+1)\n",
    "            X_train, y_train = load_BCI2a_data(path, subject+1, True)\n",
    "            X_test, y_test = load_BCI2a_data(path, subject+1, False)\n",
    "        elif (dataset == 'CS2R'):\n",
    "            X_train, y_train, _, _, _ = load_CS2R_data_v2(path, subject, True, classes_labels)\n",
    "            X_test, y_test, _, _, _ = load_CS2R_data_v2(path, subject, False, classes_labels)\n",
    "        # elif (dataset == 'HGD'):\n",
    "        #     X_train, y_train = load_HGD_data(path, subject+1, True)\n",
    "        #     X_test, y_test = load_HGD_data(path, subject+1, False)\n",
    "        else:\n",
    "            raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "\n",
    "    # shuffle the data \n",
    "    if isShuffle:\n",
    "        X_train, y_train = shuffle(X_train, y_train,random_state=42)\n",
    "        X_test, y_test = shuffle(X_test, y_test,random_state=42)\n",
    "\n",
    "    # Prepare training data     \n",
    "    N_tr, N_ch, T = X_train.shape \n",
    "    X_train = X_train.reshape(N_tr, 1, N_ch, T)\n",
    "    y_train_onehot = to_categorical(y_train)\n",
    "    # Prepare testing data \n",
    "    N_tr, N_ch, T = X_test.shape \n",
    "    X_test = X_test.reshape(N_tr, 1, N_ch, T)\n",
    "    y_test_onehot = to_categorical(y_test)    \n",
    "    \n",
    "    # Standardize the data\n",
    "    if isStandard:\n",
    "        X_train, X_test = standardize_data(X_train, X_test, N_ch)\n",
    "\n",
    "    return X_train, y_train, y_train_onehot, X_test, y_test, y_test_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining The Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Conv_block (Models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_block_(input_layer, F1=4, kernLength=64, poolSize=8, D=2, in_chans=22, \n",
    "                weightDecay = 0.009, maxNorm = 0.6, dropout=0.25):\n",
    "    \"\"\" Conv_block\n",
    "    \n",
    "        Notes\n",
    "        -----\n",
    "        using  different regularization methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    F2= F1*D\n",
    "    block1 = Conv2D(F1, (kernLength, 1), padding = 'same', data_format='channels_last', \n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    \n",
    "                    # In a Conv2D layer with data_format=\"channels_last\", the weight tensor has shape \n",
    "                    # (rows, cols, input_depth, output_depth), set axis to [0, 1, 2] to constrain \n",
    "                    # the weights of each filter tensor of size (rows, cols, input_depth).\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1,2]),\n",
    "                    use_bias = False)(input_layer)\n",
    "    block1 = BatchNormalization(axis = -1)(block1)  # bn_axis = -1 if data_format() == 'channels_last' else 1\n",
    "    \n",
    "    block2 = DepthwiseConv2D((1, in_chans),  \n",
    "                             depth_multiplier = D,\n",
    "                             data_format='channels_last',\n",
    "                             depthwise_regularizer=L2(weightDecay),\n",
    "                             depthwise_constraint  = max_norm(maxNorm, axis=[0,1,2]),\n",
    "                             use_bias = False)(block1)\n",
    "    block2 = BatchNormalization(axis = -1)(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = AveragePooling2D((8,1),data_format='channels_last')(block2)\n",
    "    block2 = Dropout(dropout)(block2)\n",
    "    \n",
    "    block3 = Conv2D(F2, (16, 1),\n",
    "                            data_format='channels_last',\n",
    "                            kernel_regularizer=L2(weightDecay),\n",
    "                            kernel_constraint = max_norm(maxNorm, axis=[0,1,2]),\n",
    "                            use_bias = False, padding = 'same')(block2)\n",
    "    block3 = BatchNormalization(axis = -1)(block3)\n",
    "    block3 = Activation('elu')(block3)\n",
    "    \n",
    "    #block3 = AveragePooling2D((poolSize,1),data_format='channels_last')(block3)\n",
    "    block3 = Dropout(dropout)(block3)\n",
    "    return block3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. attention_block (Model.py  ------>  attention_models.py)\n",
    "\n",
    "attention_block takes dependancies from attention_module.py. This has three types of attention mechanisms used.\n",
    "1. Multihead Self Attention - mha_block\n",
    "2. Squeeze and Excitation Attention - se_block\n",
    "3. Covolutional Block Attention - cbam_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. mha_block. Best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mha_block(input_feature, key_dim=32, num_heads=10, dropout = 0.5, vanilla = True):\n",
    "    \"\"\"Multi Head self Attention (MHA) block.     \n",
    "       \n",
    "    Here we include two types of MHA blocks: \n",
    "            The original multi-head self-attention as described in https://arxiv.org/abs/1706.03762\n",
    "            The multi-head local self attention as described in https://arxiv.org/abs/2112.13492v1\n",
    "    \"\"\"    \n",
    "    # Layer normalization\n",
    "    print(\"input_feature.shape before layer normalization:\", input_feature.shape, type(input_feature))\n",
    "\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(input_feature)\n",
    "\n",
    "\n",
    "    print(\"key_dim & num_heads\", key_dim, num_heads)\n",
    "    print(\"x.shape after layer normalization:\", x.shape, type(x))\n",
    "\n",
    "\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])\n",
    "    print(\"x after reshaping\", x.shape)\n",
    "\n",
    "\n",
    "    x = MultiHeadAttention(key_dim = key_dim, num_heads = num_heads, dropout = dropout)(x, x)\n",
    "\n",
    "\n",
    "    print(\"x after multihead attention\", x.shape)\n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    # Skip connection\n",
    "\n",
    "\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])\n",
    "    print(\"X:\", x.shape)\n",
    "    print(\"INPUTFEATURES:\", input_feature.shape)\n",
    "\n",
    "    \n",
    "    mha_feature = Add()([input_feature, x])\n",
    "    \n",
    "    return mha_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My MHA Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nclass EmbeddingLayer(tf.keras.layers.Layer):\\n    def __init__(self, output_dim, **kwargs):\\n        super(EmbeddingLayer, self).__init__(**kwargs)\\n        self.output_dim = output_dim\\n        self.embedding = Dense(output_dim)\\n\\n    def call(self, inputs):\\n        # Assuming inputs has shape (batch_size, seq_len, num_features)\\n        batch_size, seq_len, num_features = inputs.shape.as_list()\\n        # Reshape inputs to (batch_size * seq_len, num_features)\\n        inputs_reshaped = tf.reshape(inputs, (batch_size * seq_len, num_features))\\n        # Apply embedding\\n        embedded_inputs = self.embedding(inputs_reshaped)\\n        # Reshape back to (batch_size, seq_len, output_dim)\\n        embedded_inputs_reshaped = tf.reshape(embedded_inputs, (batch_size, seq_len, self.output_dim))\\n        return embedded_inputs_reshaped\\n\\ndef mha_block(input_feature, key_dim=8, num_heads=2, dropout=0.5):\\n    \"\"\"Multi Head self Attention (MHA) block.\\n       \\n    Here we include two types of MHA blocks:\\n        - The original multi-head self-attention as described in https://arxiv.org/abs/1706.03762\\n        - The multi-head local self attention as described in https://arxiv.org/abs/2112.13492v1\\n    \"\"\"    \\n\\n    # Apply embedding layer logic here\\n    # Assume embedding_layer is your custom embedding layer\\n    x = EmbeddingLayer(output_dim=input_feature.shape[-1])(input_feature)\\n\\n    # Perform attention\\n    x = LayerNormalization(epsilon=1e-6)(x)\\n    x = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout)(x, x)\\n\\n    # Dropout\\n    x = Dropout(dropout)(x)\\n    \\n    # Skip connection\\n    mha_feature = Add()([input_feature, x])\\n    \\n    return mha_feature\\n\\n\\n    \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "class EmbeddingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super(EmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Assuming inputs has shape (batch_size, seq_len, num_features)\n",
    "        batch_size, seq_len, num_features = inputs.shape.as_list()\n",
    "        # Reshape inputs to (batch_size * seq_len, num_features)\n",
    "        inputs_reshaped = tf.reshape(inputs, (batch_size * seq_len, num_features))\n",
    "        # Apply embedding\n",
    "        embedded_inputs = self.embedding(inputs_reshaped)\n",
    "        # Reshape back to (batch_size, seq_len, output_dim)\n",
    "        embedded_inputs_reshaped = tf.reshape(embedded_inputs, (batch_size, seq_len, self.output_dim))\n",
    "        return embedded_inputs_reshaped\n",
    "\n",
    "def mha_block(input_feature, key_dim=8, num_heads=2, dropout=0.5):\n",
    "    \"\"\"Multi Head self Attention (MHA) block.\n",
    "       \n",
    "    Here we include two types of MHA blocks:\n",
    "        - The original multi-head self-attention as described in https://arxiv.org/abs/1706.03762\n",
    "        - The multi-head local self attention as described in https://arxiv.org/abs/2112.13492v1\n",
    "    \"\"\"    \n",
    "\n",
    "    # Apply embedding layer logic here\n",
    "    # Assume embedding_layer is your custom embedding layer\n",
    "    x = EmbeddingLayer(output_dim=input_feature.shape[-1])(input_feature)\n",
    "\n",
    "    # Perform attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout)(x, x)\n",
    "\n",
    "    # Dropout\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    # Skip connection\n",
    "    mha_feature = Add()([input_feature, x])\n",
    "    \n",
    "    return mha_feature\n",
    "\n",
    "\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. se_block (Squeeze and Excitation Block). Not need to be replicated since the best performance is from mha_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(input_feature, ratio=8, residual = False, apply_to_input=True):\n",
    "    \"\"\"Squeeze-and-Excitation(SE) block.\n",
    "    \n",
    "    As described in https://arxiv.org/abs/1709.01507\n",
    "    The implementation is taken from https://github.com/kobiso/CBAM-keras\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    se_feature = GlobalAveragePooling2D()(input_feature)\n",
    "    se_feature = Reshape((1, 1, channel))(se_feature)\n",
    "    assert se_feature.shape[1:] == (1,1,channel)\n",
    "    if (ratio != 0):\n",
    "        se_feature = Dense(channel // ratio,\n",
    "                           activation='relu',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           use_bias=True,\n",
    "                           bias_initializer='zeros')(se_feature)\n",
    "        assert se_feature.shape[1:] == (1,1,channel//ratio)\n",
    "    se_feature = Dense(channel,\n",
    "                       activation='sigmoid',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       use_bias=True,\n",
    "                       bias_initializer='zeros')(se_feature)\n",
    "    assert se_feature.shape[1:] == (1,1,channel)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se_feature = Permute((3, 1, 2))(se_feature)\n",
    "        \n",
    "    if(apply_to_input):\n",
    "        se_feature = multiply([input_feature, se_feature])\n",
    "    \n",
    "    # Residual Connection\n",
    "    if(residual): \n",
    "        se_feature = Add()([se_feature, input_feature])\n",
    "\n",
    "    return se_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. cbam_block (Convlusional Block Attention Module). Not need to be replicated since the best performance is from mha_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "    \n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)    \n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "        \n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "#     channel = input_feature._keras_shape[channel_axis]\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "    \n",
    "    shared_layer_one = Dense(channel//ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "    avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    \n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    \n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "    \n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    \n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(input_feature, ratio=8, residual = False):\n",
    "    \"\"\" Convolutional Block Attention Module(CBAM) block.\n",
    "    \n",
    "    As described in https://arxiv.org/abs/1807.06521\n",
    "    The implementation is taken from https://github.com/kobiso/CBAM-keras\n",
    "    \"\"\"\n",
    "    \n",
    "    cbam_feature = channel_attention(input_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    \n",
    "    # Residual Connection\n",
    "    if(residual): \n",
    "        cbam_feature = Add()([input_feature, cbam_feature])\n",
    "\n",
    "    return cbam_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Attention_block that combines all three attention mechanisms into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(in_layer, attention_model, ratio=8, residual = False, apply_to_input=True): \n",
    "    in_sh = in_layer.shape # dimensions of the input tensor\n",
    "    in_len = len(in_sh) \n",
    "    expanded_axis = 2 # defualt = 2\n",
    "    \n",
    "    if attention_model == 'mha':   # Multi-head self attention layer \n",
    "        if(in_len > 3):\n",
    "            in_layer = Reshape((in_sh[1],-1))(in_layer)\n",
    "        out_layer = mha_block(in_layer)\n",
    "    else:\n",
    "        raise Exception(\"'{}' is not supported attention module!\".format(attention_model))\n",
    "        \n",
    "    if (in_len == 3 and len(out_layer.shape) == 4):\n",
    "        out_layer = tf.squeeze(out_layer, expanded_axis)\n",
    "    elif (in_len == 4 and len(out_layer.shape) == 3):\n",
    "        out_layer = Reshape((in_sh[1], in_sh[2], in_sh[3]))(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. TCN_block (Models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCN_block_(input_layer,input_dimension,depth,kernel_size,filters, dropout,\n",
    "               weightDecay = 0.009, maxNorm = 0.6, activation='relu'):\n",
    "    \"\"\" TCN_block from Bai et al 2018\n",
    "        Temporal Convolutional Network (TCN)\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        using different regularization methods\n",
    "    \"\"\"    \n",
    "    \n",
    "    block = Conv1D(filters, kernel_size=kernel_size, dilation_rate=1, activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "                    \n",
    "                    padding = 'causal',kernel_initializer='he_uniform')(input_layer)\n",
    "    block = BatchNormalization()(block)\n",
    "    block = Activation(activation)(block)\n",
    "    block = Dropout(dropout)(block)\n",
    "    block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=1,activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "\n",
    "                    padding = 'causal',kernel_initializer='he_uniform')(block)\n",
    "    block = BatchNormalization()(block)\n",
    "    block = Activation(activation)(block)\n",
    "    block = Dropout(dropout)(block)\n",
    "    if(input_dimension != filters):\n",
    "        conv = Conv1D(filters,kernel_size=1,\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "                      \n",
    "                    padding='same')(input_layer)\n",
    "        added = Add()([block,conv])\n",
    "    else:\n",
    "        added = Add()([block,input_layer])\n",
    "    out = Activation(activation)(added)\n",
    "    \n",
    "    for i in range(depth-1):\n",
    "        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "                    \n",
    "                   padding = 'causal',kernel_initializer='he_uniform')(out)\n",
    "        block = BatchNormalization()(block)\n",
    "        block = Activation(activation)(block)\n",
    "        block = Dropout(dropout)(block)\n",
    "        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',\n",
    "                    kernel_regularizer=L2(weightDecay),\n",
    "                    kernel_constraint = max_norm(maxNorm, axis=[0,1]),\n",
    "\n",
    "                    padding = 'causal',kernel_initializer='he_uniform')(block)\n",
    "        block = BatchNormalization()(block)\n",
    "        block = Activation(activation)(block)\n",
    "        block = Dropout(dropout)(block)\n",
    "        added = Add()([block, out])\n",
    "        out = Activation(activation)(added)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. ATCNet architecture that uses Conv_block, attention_block and TCN_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATCNet_(n_classes, in_chans = 22, in_samples = 1125, n_windows = 5, attention = 'mha', \n",
    "           eegn_F1 = 16, eegn_D = 2, eegn_kernelSize = 64, eegn_poolSize = 7, eegn_dropout=0.3, \n",
    "           tcn_depth = 2, tcn_kernelSize = 4, tcn_filters = 32, tcn_dropout = 0.3, \n",
    "           tcn_activation = 'elu', fuse = 'average'):\n",
    "    \n",
    "    \"\"\" ATCNet model from Altaheri et al 2023.\n",
    "        See details at https://ieeexplore.ieee.org/abstract/document/9852687\n",
    "    \n",
    "        Notes\n",
    "        -----\n",
    "        The initial values in this model are based on the values identified by\n",
    "        the authors\n",
    "        \n",
    "        References\n",
    "        ----------\n",
    "        .. H. Altaheri, G. Muhammad, and M. Alsulaiman. \"Physics-informed \n",
    "           attention temporal convolutional network for EEG-based motor imagery \n",
    "           classification.\" IEEE Transactions on Industrial Informatics, \n",
    "           vol. 19, no. 2, pp. 2249-2258, (2023) \n",
    "           https://doi.org/10.1109/TII.2022.3197419\n",
    "    \"\"\"\n",
    "    input_1 = Input(shape = (1,in_chans, in_samples))   #     TensorShape([None, 1, 22, 1125])\n",
    "    input_2 = Permute((3,2,1))(input_1) \n",
    "\n",
    "    dense_weightDecay = 0.5  \n",
    "    conv_weightDecay = 0.009\n",
    "    conv_maxNorm = 0.6\n",
    "    from_logits = False\n",
    "\n",
    "    numFilters = eegn_F1\n",
    "    F2 = numFilters*eegn_D\n",
    "\n",
    "    print(\"input1.shape\", input_1.shape)\n",
    "    print(\"input2.shape\", input_2.shape)\n",
    "\n",
    "    block1 = Conv_block_(input_layer = input_2, F1 = eegn_F1, D = eegn_D, \n",
    "                        kernLength = eegn_kernelSize, poolSize = eegn_poolSize,\n",
    "                        weightDecay = conv_weightDecay, maxNorm = conv_maxNorm,\n",
    "                        in_chans = in_chans, dropout = eegn_dropout)\n",
    "    \n",
    "    print(\"block1 after convlusion:\", block1.shape)\n",
    "    \n",
    "    block1 = Lambda(lambda x: x[:,:,-1,:])(block1)\n",
    "       \n",
    "    print(\"block1 after lambda:\", block1.shape)\n",
    "\n",
    "    # Sliding window \n",
    "    sw_concat = []   # to store concatenated or averaged sliding window outputs\n",
    "    for i in range(n_windows):\n",
    "        st = i\n",
    "        end = block1.shape[1]-n_windows+i+1\n",
    "\n",
    "        print(\"n_windows\", n_windows,\"i:\", i, \"st:\", st, \"end:\", end)\n",
    "\n",
    "        block2 = block1[:, st:end, :]\n",
    "        \n",
    "\n",
    "        print(\"block2 before attention:\", block2.shape)\n",
    "\n",
    "        # Attention_model\n",
    "        if attention is not None:\n",
    "            if (attention == 'se' or attention == 'cbam'):\n",
    "                block2 = Permute((2, 1))(block2) # shape=(None, 32, 16)\n",
    "                block2 = attention_block(block2, attention)\n",
    "                block2 = Permute((2, 1))(block2) # shape=(None, 16, 32)\n",
    "            else: block2 = attention_block(block2, attention)\n",
    "\n",
    "        # Temporal convolutional network (TCN)\n",
    "        print(\"block2 before TCN:\", block2.shape)\n",
    "        block3 = TCN_block_(input_layer = block2, input_dimension = F2, depth = tcn_depth,\n",
    "                            kernel_size = tcn_kernelSize, filters = tcn_filters, \n",
    "                            weightDecay = conv_weightDecay, maxNorm = conv_maxNorm,\n",
    "                            dropout = tcn_dropout, activation = tcn_activation)\n",
    "        # Get feature maps of the last sequence\n",
    "        block3 = Lambda(lambda x: x[:,-1,:])(block3)\n",
    "        \n",
    "        print(\"block3 after TCN:\", block3.shape)\n",
    "\n",
    "        # Outputs of sliding window: Average_after_dense or concatenate_then_dense\n",
    "        if(fuse == 'average'):\n",
    "            sw_concat.append(Dense(n_classes, kernel_regularizer=L2(dense_weightDecay))(block3))\n",
    "        elif(fuse == 'concat'):\n",
    "            if i == 0:\n",
    "                sw_concat = block3\n",
    "            else:\n",
    "                sw_concat = Concatenate()([sw_concat, block3])\n",
    "    \n",
    "    \n",
    "    print(\"sw_concat before fuse:\", len(sw_concat))\n",
    "\n",
    "\n",
    "    if(fuse == 'average'):\n",
    "        if len(sw_concat) > 1: # more than one window\n",
    "            sw_concat = tf.keras.layers.Average()(sw_concat[:])\n",
    "        else: # one window (# windows = 1)\n",
    "            sw_concat = sw_concat[0]\n",
    "    elif(fuse == 'concat'):\n",
    "        sw_concat = Dense(n_classes, kernel_regularizer=L2(dense_weightDecay))(sw_concat)\n",
    "\n",
    "\n",
    "    if from_logits:  # No activation here because we are using from_logits=True\n",
    "        out = Activation('linear', name = 'linear')(sw_concat)\n",
    "    else:   # Using softmax activation\n",
    "        out = Activation('softmax', name = 'softmax')(sw_concat)\n",
    "    \n",
    "    print(\"out:\", out)\n",
    "\n",
    "    return Model(inputs = input_1, outputs = out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Selecting Which Model to Run  \n",
    "\n",
    "This does not matter to us if we are only looking to run ATCNet Model. The additional models are commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name, dataset_conf, from_logits = False):\n",
    "    \n",
    "    n_classes = dataset_conf.get('n_classes')\n",
    "    n_channels = dataset_conf.get('n_channels')\n",
    "    in_samples = dataset_conf.get('in_samples')\n",
    "\n",
    "    # Select the model\n",
    "    if(model_name == 'ATCNet'):\n",
    "        # Train using the proposed ATCNet model: https://ieeexplore.ieee.org/document/9852687\n",
    "        model = ATCNet_( \n",
    "            # Dataset parameters\n",
    "            n_classes = n_classes, \n",
    "            in_chans = n_channels, \n",
    "            in_samples = in_samples, \n",
    "            # Sliding window (SW) parameter\n",
    "            n_windows = 1, \n",
    "            # Attention (AT) block parameter\n",
    "            attention = 'mha', # Options: None, 'mha','mhla', 'cbam', 'se'\n",
    "            # Convolutional (CV) block parameters\n",
    "            eegn_F1 = 16,\n",
    "            eegn_D = 2, \n",
    "            eegn_kernelSize = 64,\n",
    "            eegn_poolSize = 7,\n",
    "            eegn_dropout = 0.3,\n",
    "            # Temporal convolutional (TC) block parameters\n",
    "            tcn_depth = 2, \n",
    "            tcn_kernelSize = 4,\n",
    "            tcn_filters = 32,\n",
    "            tcn_dropout = 0.3, \n",
    "            tcn_activation='elu',\n",
    "            )     \n",
    "    # elif(model_name == 'TCNet_Fusion'):\n",
    "    #     # Train using TCNet_Fusion: https://doi.org/10.1016/j.bspc.2021.102826\n",
    "    #     model = models.TCNet_Fusion(n_classes = n_classes, Chans=n_channels, Samples=in_samples)      \n",
    "    # elif(model_name == 'EEGTCNet'):\n",
    "    #     # Train using EEGTCNet: https://arxiv.org/abs/2006.00622\n",
    "    #     model = models.EEGTCNet(n_classes = n_classes, Chans=n_channels, Samples=in_samples)          \n",
    "    # elif(model_name == 'EEGNet'):\n",
    "    #     # Train using EEGNet: https://arxiv.org/abs/1611.08024\n",
    "    #     model = models.EEGNet_classifier(n_classes = n_classes, Chans=n_channels, Samples=in_samples) \n",
    "    # elif(model_name == 'EEGNeX'):\n",
    "    #     # Train using EEGNeX: https://arxiv.org/abs/2207.12369\n",
    "    #     model = models.EEGNeX_8_32(n_timesteps = in_samples , n_features = n_channels, n_outputs = n_classes)\n",
    "    # elif(model_name == 'DeepConvNet'):\n",
    "    #     # Train using DeepConvNet: https://doi.org/10.1002/hbm.23730\n",
    "    #     model = models.DeepConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "    # elif(model_name == 'ShallowConvNet'):\n",
    "    #     # Train using ShallowConvNet: https://doi.org/10.1002/hbm.23730\n",
    "    #     model = models.ShallowConvNet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "    # elif(model_name == 'MBEEG_SENet'):\n",
    "    #     # Train using MBEEG_SENet: https://www.mdpi.com/2075-4418/12/4/995\n",
    "    #     model = models.MBEEG_SENet(nb_classes = n_classes , Chans = n_channels, Samples = in_samples)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"'{}' model is not supported yet!\".format(model_name))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Drawing Curves for the Learning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_learning_curves(history, sub):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy - subject: ' + str(sub))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss - subject: ' + str(sub))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Trai Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset_conf, train_conf, results_path):\n",
    "    \n",
    "    # remove the 'result' folder before training\n",
    "    if os.path.exists(results_path):\n",
    "        # Remove the folder and its contents\n",
    "        shutil.rmtree(results_path)\n",
    "        os.makedirs(results_path)        \n",
    "\n",
    "    # Get the current 'IN' time to calculate the overall training time\n",
    "    in_exp = time.time()\n",
    "    # Create a file to store the path of the best model among several runs\n",
    "    best_models = open(results_path + \"/best models.txt\", \"w\")\n",
    "    # Create a file to store performance during training\n",
    "    log_write = open(results_path + \"/log.txt\", \"w\")\n",
    "    \n",
    "    # Get dataset paramters\n",
    "    dataset = dataset_conf.get('name')\n",
    "    n_sub = dataset_conf.get('n_sub')\n",
    "    data_path = dataset_conf.get('data_path')\n",
    "    isStandard = dataset_conf.get('isStandard')\n",
    "    LOSO = dataset_conf.get('LOSO')\n",
    "    # Get training hyperparamters\n",
    "    batch_size = train_conf.get('batch_size')\n",
    "    epochs = train_conf.get('epochs')\n",
    "    patience = train_conf.get('patience')\n",
    "    lr = train_conf.get('lr')\n",
    "    LearnCurves = train_conf.get('LearnCurves') # Plot Learning Curves?\n",
    "    n_train = train_conf.get('n_train')\n",
    "    model_name = train_conf.get('model')\n",
    "    from_logits = train_conf.get('from_logits') \n",
    "\n",
    "    # Initialize variables\n",
    "    acc = np.zeros((n_sub, n_train))\n",
    "    kappa = np.zeros((n_sub, n_train))\n",
    "    \n",
    "    # Iteration over subjects \n",
    "    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "\n",
    "        print('\\nTraining on subject ', sub+1)\n",
    "        log_write.write( '\\nTraining on subject '+ str(sub+1) +'\\n')\n",
    "        # Initiating variables to save the best subject accuracy among multiple runs.\n",
    "        BestSubjAcc = 0 \n",
    "        bestTrainingHistory = [] \n",
    "        \n",
    "        # Get training and test data\n",
    "        X_train, _, y_train_onehot, _, _, _ = get_data(\n",
    "            data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)\n",
    "         \n",
    "        # Divide the training data into training and validation\n",
    "        X_train, X_val, y_train_onehot, y_val_onehot = train_test_split(X_train, y_train_onehot, test_size=0.2, random_state=42)       \n",
    "        \n",
    "        # Iteration over multiple runs \n",
    "        for train in range(n_train): # How many repetitions of training for subject i.\n",
    "            # Set the random seed for TensorFlow and NumPy random number generator. \n",
    "            # The purpose of setting a seed is to ensure reproducibility in random operations. \n",
    "            tf.random.set_seed(train+1)\n",
    "            np.random.seed(train+1)\n",
    "            \n",
    "            # Get the current 'IN' time to calculate the 'run' training time\n",
    "            in_run = time.time()\n",
    "            \n",
    "            # Create folders and files to save trained models for all runs\n",
    "            filepath = results_path + '/saved models/run-{}'.format(train+1)\n",
    "            if not os.path.exists(filepath):\n",
    "                os.makedirs(filepath)        \n",
    "            filepath = filepath + '/subject-{}.h5'.format(sub+1)\n",
    "            \n",
    "            # Create the model\n",
    "            model = getModel(model_name, dataset_conf, from_logits)\n",
    "            # Compile and train the model\n",
    "            model.compile(loss=CategoricalCrossentropy(from_logits=from_logits), optimizer=Adam(learning_rate=lr), metrics=['accuracy'])          \n",
    "\n",
    "            model.summary()\n",
    "            #plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                                save_best_only=True, save_weights_only=True, mode='min'),\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.90, patience=20, verbose=0, min_lr=0.0001),  \n",
    "                # EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\n",
    "            ]\n",
    "            history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), \n",
    "                                epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=0)\n",
    "           \n",
    "            # Evaluate the performance of the trained model based on the validation data\n",
    "            # Here we load the Trained weights from the file saved in the hard \n",
    "            # disk, which should be the same as the weights of the current model.\n",
    "            model.load_weights(filepath)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            if from_logits:\n",
    "                y_pred = tf.nn.softmax(y_pred).numpy().argmax(axis=-1)\n",
    "            else:\n",
    "                y_pred = y_pred.argmax(axis=-1)\n",
    "                \n",
    "            labels = y_val_onehot.argmax(axis=-1)\n",
    "            acc[sub, train]  = accuracy_score(labels, y_pred)\n",
    "            kappa[sub, train] = cohen_kappa_score(labels, y_pred)\n",
    "                        \n",
    "            # Get the current 'OUT' time to calculate the 'run' training time\n",
    "            out_run = time.time()\n",
    "            # Print & write performance measures for each run\n",
    "            info = 'Subject: {}   seed {}   time: {:.1f} m   '.format(sub+1, train+1, ((out_run-in_run)/60))\n",
    "            info = info + 'valid_acc: {:.4f}   valid_loss: {:.3f}'.format(acc[sub, train], min(history.history['val_loss']))\n",
    "            print(info)\n",
    "            log_write.write(info +'\\n')\n",
    "            # If current training run is better than previous runs, save the history.\n",
    "            if(BestSubjAcc < acc[sub, train]):\n",
    "                 BestSubjAcc = acc[sub, train]\n",
    "                 bestTrainingHistory = history\n",
    "        \n",
    "        # Store the path of the best model among several runs\n",
    "        best_run = np.argmax(acc[sub,:])\n",
    "        filepath = '/saved models/run-{}/subject-{}.h5'.format(best_run+1, sub+1)+'\\n'\n",
    "        best_models.write(filepath)\n",
    "\n",
    "        # Plot Learning curves \n",
    "        if (LearnCurves == True):\n",
    "            print('Plot Learning Curves ....... ')\n",
    "            draw_learning_curves(bestTrainingHistory, sub+1)\n",
    "          \n",
    "    # Get the current 'OUT' time to calculate the overall training time\n",
    "    out_exp = time.time()\n",
    "           \n",
    "    # Print & write the validation performance using all seeds\n",
    "    head1 = head2 = '         '\n",
    "    for sub in range(n_sub): \n",
    "        head1 = head1 + 'sub_{}   '.format(sub+1)\n",
    "        head2 = head2 + '-----   '\n",
    "    head1 = head1 + '  average'\n",
    "    head2 = head2 + '  -------'\n",
    "    info = '\\n---------------------------------\\nValidation performance (acc %):'\n",
    "    info = info + '\\n---------------------------------\\n' + head1 +'\\n'+ head2\n",
    "    for run in range(n_train): \n",
    "        info = info + '\\nSeed {}:  '.format(run+1)\n",
    "        for sub in range(n_sub): \n",
    "            info = info + '{:.2f}   '.format(acc[sub, run]*100)\n",
    "        info = info + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n",
    "    info = info + '\\n---------------------------------\\nAverage acc - all seeds: '\n",
    "    info = info + '{:.2f} %\\n\\nTrain Time  - all seeds: {:.1f}'.format(np.average(acc)*100, (out_exp-in_exp)/(60))\n",
    "    info = info + ' min\\n---------------------------------\\n'\n",
    "    print(info)\n",
    "    log_write.write(info+'\\n')\n",
    "\n",
    "    # Close open files \n",
    "    best_models.close()   \n",
    "    log_write.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Running the training cycle. Do not know why but the dataset with it's mat files should be put inside a /datasets1 folder inside the current directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on subject  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.shape (None, 1, 22, 1125)\n",
      "input2.shape (None, 1125, 22, 1)\n",
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 23:48:01.843325: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-20 23:48:01.843356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1 after convlusion: (None, 140, 1, 32)\n",
      "block1 after lambda: (None, 140, 32)\n",
      "n_windows 1 i: 0 st: 0 end: 140\n",
      "block2 before attention: (None, 140, 32)\n",
      "input_feature.shape before layer normalization: (None, 140, 32) <class 'keras.engine.keras_tensor.KerasTensor'>\n",
      "key_dim & num_heads 32 10\n",
      "x.shape after layer normalization: (None, 140, 32) <class 'keras.engine.keras_tensor.KerasTensor'>\n",
      "x after reshaping (None, 32, 140)\n",
      "x after multihead attention (None, 32, 140)\n",
      "X: (None, 140, 32)\n",
      "INPUTFEATURES: (None, 140, 32)\n",
      "block2 before TCN: (None, 140, 32)\n",
      "block3 after TCN: (None, 32)\n",
      "sw_concat before fuse: 1\n",
      "out: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name=None), name='softmax/Softmax:0', description=\"created by layer 'softmax'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 22, 1125  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 1125, 22, 1)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 1125, 22, 16  1024        ['permute[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1125, 22, 16  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 1125, 1, 32)  704        ['batch_normalization[0][0]']    \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1125, 1, 32)  128        ['depthwise_conv2d[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1125, 1, 32)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 140, 1, 32)  0           ['activation[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 140, 1, 32)   0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 140, 1, 32)   16384       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 140, 1, 32)  128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 140, 1, 32)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 140, 1, 32)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 140, 32)      0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 140, 32)     0           ['lambda[0][0]']                 \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 140, 32)     64          ['tf.__operators__.getitem[0][0]'\n",
      " alization)                                                      ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 32, 140)     0           ['layer_normalization[0][0]']    \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 32, 140)     180300      ['tf.compat.v1.transpose[0][0]', \n",
      " dAttention)                                                      'tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 140)      0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 140, 32)     0           ['dropout_2[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 140, 32)      0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.compat.v1.transpose_1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 140, 32)      4128        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 140, 32)     128         ['conv1d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 140, 32)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 140, 32)      0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 140, 32)      4128        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 140, 32)     128         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 140, 32)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 140, 32)      0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 140, 32)      0           ['dropout_4[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 140, 32)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 140, 32)      4128        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 140, 32)     128         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 140, 32)      0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 140, 32)      0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 140, 32)      4128        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 140, 32)     128         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 140, 32)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 140, 32)      0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 140, 32)      0           ['dropout_6[0][0]',              \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 140, 32)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 32)           0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            132         ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 4)            0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,952\n",
      "Trainable params: 215,536\n",
      "Non-trainable params: 416\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 23:48:02.586810: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-04-20 23:48:04.386285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-04-20 23:48:09.440038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m train_conf \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_train\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     45\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearnCurves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_logits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATCNet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#Train the model\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 83\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset_conf, train_conf, results_path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#plot_model(model, to_file='plot_model.png', show_shapes=True, show_layer_names=True)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     78\u001b[0m     ModelCheckpoint(filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m     79\u001b[0m                     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     80\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.90\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),  \n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=patience)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m ]\n\u001b[0;32m---> 83\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_onehot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Evaluate the performance of the trained model based on the validation data\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Here we load the Trained weights from the file saved in the hard \u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# disk, which should be the same as the weights of the current model.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(filepath)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define dataset parameters\n",
    "dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n",
    "\n",
    "if dataset == 'BCI2a': \n",
    "    in_samples = 1125\n",
    "    n_channels = 22\n",
    "    n_sub = 9\n",
    "    n_classes = 4\n",
    "    classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
    "    #data_path = os.path.expanduser('~') + '/BCI Competition IV/BCI Competition IV-2a/BCI Competition IV 2a mat/'\n",
    "    data_path = os.path.expanduser('~') + '/Mac/Codes/FYP_Codes/BCI-Competition-IV/dataset'\n",
    "\n",
    "# elif dataset == 'HGD': \n",
    "#     in_samples = 1125\n",
    "#     n_channels = 44\n",
    "#     n_sub = 14\n",
    "#     n_classes = 4\n",
    "#     classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']     \n",
    "#     data_path = os.path.expanduser('~') + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n",
    "# elif dataset == 'CS2R': \n",
    "#     in_samples = 1125\n",
    "#     # in_samples = 576\n",
    "#     n_channels = 32\n",
    "#     n_sub = 18\n",
    "#     n_classes = 3\n",
    "#     # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']     \n",
    "#     classes_labels = ['Fingers', 'Wrist','Elbow']     \n",
    "#     # classes_labels = ['Fingers', 'Elbow']     \n",
    "#     data_path = os.path.expanduser('~') + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n",
    "else:\n",
    "    raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "    \n",
    "# Create a folder to store the results of the experiment\n",
    "results_path = os.getcwd() + \"/results\"\n",
    "if not  os.path.exists(results_path):\n",
    "    os.makedirs(results_path)   # Create a new directory if it does not exist \n",
    "    \n",
    "# Set dataset paramters \n",
    "dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n",
    "                'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n",
    "                'data_path': data_path, 'isStandard': True, 'LOSO': False}\n",
    "\n",
    "# Set training hyperparamters\n",
    "train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n",
    "                'LearnCurves': True, 'from_logits': False, 'model':'ATCNet'}\n",
    "\n",
    "#Train the model\n",
    "train(dataset_conf, train_conf, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Drawing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(cf_matrix, sub, results_path, classes_labels):\n",
    "    # Generate confusion matrix plot\n",
    "    display_labels = classes_labels\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, \n",
    "                                display_labels=display_labels)\n",
    "    disp.plot()\n",
    "    disp.ax_.set_xticklabels(display_labels, rotation=12)\n",
    "    plt.title('Confusion Matrix of Subject: ' + sub )\n",
    "    plt.savefig(results_path + '/subject_' + sub + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Drawing Performance BarChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_performance_barChart(num_sub, metric, label):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = list(range(1, num_sub+1))\n",
    "    ax.bar(x, metric, 0.5, label=label)\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_xlabel(\"Subject\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_title('Model '+ label + ' per subject')\n",
    "    ax.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset_conf, results_path, allRuns = True):\n",
    "    # Open the  \"Log\" file to write the evaluation results \n",
    "    log_write = open(results_path + \"/log.txt\", \"a\")\n",
    "    \n",
    "    # Get dataset paramters\n",
    "    dataset = dataset_conf.get('name')\n",
    "    n_classes = dataset_conf.get('n_classes')\n",
    "    n_sub = dataset_conf.get('n_sub')\n",
    "    data_path = dataset_conf.get('data_path')\n",
    "    isStandard = dataset_conf.get('isStandard')\n",
    "    LOSO = dataset_conf.get('LOSO')\n",
    "    classes_labels = dataset_conf.get('cl_labels')\n",
    "     \n",
    "    # Test the performance based on several runs (seeds)\n",
    "    runs = os.listdir(results_path+\"/saved models\") \n",
    "    # Initialize variables\n",
    "    acc = np.zeros((n_sub, len(runs)))\n",
    "    kappa = np.zeros((n_sub, len(runs)))\n",
    "    cf_matrix = np.zeros([n_sub, len(runs), n_classes, n_classes])\n",
    "\n",
    "    # Iteration over subjects \n",
    "    # for sub in range(n_sub-1, n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "    inference_time = 0 #  inference_time: classification time for one trial\n",
    "    for sub in range(n_sub): # (num_sub): for all subjects, (i-1,i): for the ith subject.\n",
    "        # Load data\n",
    "        _, _, _, X_test, _, y_test_onehot = get_data(data_path, sub, dataset, LOSO = LOSO, isStandard = isStandard)     \n",
    "\n",
    "        # Iteration over runs (seeds) \n",
    "        for seed in range(len(runs)): \n",
    "            # Load the model of the seed.\n",
    "            model.load_weights('{}/saved models/{}/subject-{}.h5'.format(results_path, runs[seed], sub+1))\n",
    "            \n",
    "            inference_time = time.time()\n",
    "            # Predict MI task\n",
    "            y_pred = model.predict(X_test).argmax(axis=-1)\n",
    "            inference_time = (time.time() - inference_time)/X_test.shape[0]\n",
    "            # Calculate accuracy and K-score          \n",
    "            labels = y_test_onehot.argmax(axis=-1)\n",
    "            acc[sub, seed]  = accuracy_score(labels, y_pred)\n",
    "            kappa[sub, seed] = cohen_kappa_score(labels, y_pred)\n",
    "            # Calculate and draw confusion matrix\n",
    "            cf_matrix[sub, seed, :, :] = confusion_matrix(labels, y_pred, normalize='true')\n",
    "            # draw_confusion_matrix(cf_matrix[sub, seed, :, :], str(sub+1), results_path, classes_labels)\n",
    "        \n",
    "    # Print & write the average performance measures for all subjects     \n",
    "    head1 = head2 = '                  '\n",
    "    for sub in range(n_sub): \n",
    "        head1 = head1 + 'sub_{}   '.format(sub+1)\n",
    "        head2 = head2 + '-----   '\n",
    "    head1 = head1 + '  average'\n",
    "    head2 = head2 + '  -------'\n",
    "    info = '\\n' + head1 +'\\n'+ head2\n",
    "    info = '\\n---------------------------------\\nTest performance (acc & k-score):\\n'\n",
    "    info = info + '---------------------------------\\n' + head1 +'\\n'+ head2\n",
    "    for run in range(len(runs)): \n",
    "        info = info + '\\nSeed {}: '.format(run+1)\n",
    "        info_acc = '(acc %)   '\n",
    "        info_k = '        (k-sco)   '\n",
    "        for sub in range(n_sub): \n",
    "            info_acc = info_acc + '{:.2f}   '.format(acc[sub, run]*100)\n",
    "            info_k = info_k + '{:.3f}   '.format(kappa[sub, run])\n",
    "        info_acc = info_acc + '  {:.2f}   '.format(np.average(acc[:, run])*100)\n",
    "        info_k = info_k + '  {:.3f}   '.format(np.average(kappa[:, run]))\n",
    "        info = info + info_acc + '\\n' + info_k\n",
    "    info = info + '\\n----------------------------------\\nAverage - all seeds (acc %): '\n",
    "    info = info + '{:.2f}\\n                    (k-sco): '.format(np.average(acc)*100)\n",
    "    info = info + '{:.3f}\\n\\nInference time: {:.2f}'.format(np.average(kappa), inference_time * 1000)\n",
    "    info = info + ' ms per trial\\n----------------------------------\\n'\n",
    "    print(info)\n",
    "    log_write.write(info+'\\n')\n",
    "         \n",
    "    # Draw a performance bar chart for all subjects \n",
    "    draw_performance_barChart(n_sub, acc.mean(1), 'Accuracy')\n",
    "    draw_performance_barChart(n_sub, kappa.mean(1), 'k-score')\n",
    "    # Draw confusion matrix for all subjects (average)\n",
    "    draw_confusion_matrix(cf_matrix.mean((0,1)), 'All', results_path, classes_labels)\n",
    "    # Close opened file    \n",
    "    log_write.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 12:12:20.209482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 107ms/step\n",
      "9/9 [==============================] - 1s 69ms/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/results/saved models/run-1/subject-3.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 49\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# train(dataset_conf, train_conf, results_path)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Evaluate the model based on the weights saved in the '/results' folder\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m getModel(train_conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m), dataset_conf)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m    \n",
      "Cell \u001b[0;32mIn[29], line 31\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, dataset_conf, results_path, allRuns)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Iteration over runs (seeds) \u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(runs)): \n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Load the model of the seed.\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/saved models/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/subject-\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     inference_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Predict MI task\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/results/saved models/run-1/subject-3.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Define dataset parameters\n",
    "dataset = 'BCI2a' # Options: 'BCI2a','HGD', 'CS2R'\n",
    "\n",
    "if dataset == 'BCI2a': \n",
    "    in_samples = 1125\n",
    "    n_channels = 22\n",
    "    n_sub = 9\n",
    "    n_classes = 4\n",
    "    classes_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
    "    data_path = '/Users/yohanabeysinghe/Mac/Codes/FYP_Codes/BCI-Competition-IV/dataset'\n",
    "# elif dataset == 'HGD': \n",
    "#     in_samples = 1125\n",
    "#     n_channels = 44\n",
    "#     n_sub = 14\n",
    "#     n_classes = 4\n",
    "#     classes_labels = ['Right Hand', 'Left Hand','Rest','Feet']     \n",
    "#     data_path = os.path.expanduser('~') + '/mne_data/MNE-schirrmeister2017-data/robintibor/high-gamma-dataset/raw/master/data/'\n",
    "# elif dataset == 'CS2R': \n",
    "#     in_samples = 1125\n",
    "#     # in_samples = 576\n",
    "#     n_channels = 32\n",
    "#     n_sub = 18\n",
    "#     n_classes = 3\n",
    "#     # classes_labels = ['Fingers', 'Wrist','Elbow','Rest']     \n",
    "#     classes_labels = ['Fingers', 'Wrist','Elbow']     \n",
    "#     # classes_labels = ['Fingers', 'Elbow']     \n",
    "#     data_path = os.path.expanduser('~') + '/CS2R MI EEG dataset/all/EDF - Cleaned - phase one (remove extra runs)/two sessions/'\n",
    "else:\n",
    "    raise Exception(\"'{}' dataset is not supported yet!\".format(dataset))\n",
    "    \n",
    "# Create a folder to store the results of the experiment\n",
    "results_path = os.getcwd() + \"/results\"\n",
    "if not  os.path.exists(results_path):\n",
    "    os.makedirs(results_path)   # Create a new directory if it does not exist \n",
    "    \n",
    "# Set dataset paramters \n",
    "dataset_conf = { 'name': dataset, 'n_classes': n_classes, 'cl_labels': classes_labels,\n",
    "                'n_sub': n_sub, 'n_channels': n_channels, 'in_samples': in_samples,\n",
    "                'data_path': data_path, 'isStandard': True, 'LOSO': False}\n",
    "# Set training hyperparamters\n",
    "train_conf = { 'batch_size': 64, 'epochs': 500, 'patience': 100, 'lr': 0.001,'n_train': 1,\n",
    "                'LearnCurves': True, 'from_logits': False, 'model':'ATCNet'}\n",
    "        \n",
    "# Train the model\n",
    "# train(dataset_conf, train_conf, results_path)\n",
    "\n",
    "# Evaluate the model based on the weights saved in the '/results' folder\n",
    "model = getModel(train_conf.get('model'), dataset_conf)\n",
    "test(model, dataset_conf, results_path)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
